{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicolassmarti/HE2_IA_P1/blob/main/RawCode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Instalación de librerias"
      ],
      "metadata": {
        "id": "BFi0uihGGzr-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalación silenciosa de librerías\n",
        "!pip install -q pandas\n",
        "!pip install -q numpy\n",
        "!pip install -q scipy\n",
        "!pip install -q matplotlib\n",
        "!pip install -q seaborn\n",
        "!pip install -q plotly\n",
        "!pip install -q yellowbrick\n",
        "!pip install -q scikit-learn\n",
        "!pip install -q imbalanced-learn\n",
        "!pip install -q tqdm\n",
        "!pip install -q joblib\n",
        "!pip install -q huggingface_hub\n",
        "!pip install -q datasets\n",
        "!pip install -q fsspec==2024.10.0\n",
        "\n",
        "SEED = 2025\n"
      ],
      "metadata": {
        "id": "6HUYPpcwGhsA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Cargar base de datos"
      ],
      "metadata": {
        "id": "pJ7X-aYbGixG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "J7AknCFS-Cip",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "d6f5f45b-5737-4deb-dd01-a87feb817df4"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "partially initialized module 'pandas' has no attribute '_pandas_parser_CAPI' (most likely due to a circular import)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-a3adc7677bd0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Importamos las librerías necesarias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    136\u001b[0m )\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplotting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtseries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_print_versions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/api/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\"\"\" public toolkit API \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m from pandas.api import (\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mindexers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0minterchange\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/api/typing/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# TODO: Can't import Styler without importing jinja2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# from pandas.io.formats.style import Styler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_json\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mJsonReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStataReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/json/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m from pandas.io.json._json import (\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mread_json\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mto_json\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mujson_dumps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mujson_loads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mparse_table_schema\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m )\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreaders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mTYPE_CHECKING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m from pandas.io.parsers.readers import (\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mTextFileReader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mTextParser\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mread_csv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mread_fwf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_libs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_libs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparsers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSTR_NA_VALUES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m from pandas.errors import (\n\u001b[1;32m     34\u001b[0m     \u001b[0mAbstractMethodError\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36minit pandas._libs.parsers\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'pandas' has no attribute '_pandas_parser_CAPI' (most likely due to a circular import)"
          ]
        }
      ],
      "source": [
        "# Importamos las librerías necesarias\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Cargamos el dataset y lo mezclamos\n",
        "dataset = load_dataset(\"13nishit/LoanApprovalPrediction\")\n",
        "print(dataset)\n",
        "\n",
        "dataset = load_dataset(\"13nishit/LoanApprovalPrediction\", streaming=True)\n",
        "df = pd.DataFrame(list(dataset['train'].shuffle(seed=2025).take(130)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Procesamiento de datos"
      ],
      "metadata": {
        "id": "Zjn8gr5nHFhp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Examinamos la información básica del DataFrame\n",
        "print(\"\\n=== Información del DataFrame ===\")\n",
        "print(df.info())\n",
        "\n",
        "# 2. Verificamos los tipos de datos y valores únicos para cada columna\n",
        "print(\"\\n=== Valores únicos por columna ===\")\n",
        "for column in df.columns:\n",
        "    print(f\"\\n{column}:\")\n",
        "    print(f\"Tipo de dato: {df[column].dtype}\")\n",
        "    print(f\"Valores únicos: {df[column].nunique()}\")\n",
        "\n",
        "# Filtrar valores nulos antes de ordenar\n",
        "    unique_values = [val for val in df[column].unique() if pd.notna(val)]\n",
        "\n",
        "    # Ordenar solo si hay valores no nulos\n",
        "    if unique_values:\n",
        "        print(f\"Primeros valores únicos: {sorted(unique_values)[:5]}\")\n",
        "    else:\n",
        "        print(\"Primeros valores únicos: No hay valores válidos\")\n",
        "\n",
        "# 3. Verificamos valores nulos\n",
        "print(\"\\n=== Valores nulos ===\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# 4. Estadísticas descriptivas básicas\n",
        "print(\"\\n=== Estadísticas descriptivas ===\")\n",
        "print(df.describe())\n",
        "\n",
        "# 5. Debalance de clases\n",
        "\n",
        "print(\"📊 Distribución de la variable objetivo (Loan_Status):\")\n",
        "class_dist = df['Loan_Status'].value_counts(normalize=True)\n",
        "print(\"\\nPorcentajes:\")\n",
        "for clase, porcentaje in class_dist.items():\n",
        "    print(f\"Clase {clase}: {porcentaje*100:.2f}%\")\n",
        "\n",
        "# Visualizamos la distribución con un gráfico de barras\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(data=df, x='Loan_Status')\n",
        "plt.title('Distribución de Defaults en la muestra')\n",
        "plt.xlabel('Default (N: No, Y: Sí)')\n",
        "plt.ylabel('Cantidad')\n",
        "\n",
        "# Añadimos los valores exactos sobre cada barra\n",
        "for i in plt.gca().containers[0]:\n",
        "    plt.text(i.get_x() + i.get_width()/2,\n",
        "            i.get_height(),\n",
        "            f'{int(i.get_height())}',\n",
        "            ha='center', va='bottom')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xZBxVIyrGlQM",
        "outputId": "ef580bd5-aba9-4fdc-b182-ae388a19d61d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Información del DataFrame ===\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 130 entries, 0 to 129\n",
            "Data columns (total 13 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   Loan_ID            130 non-null    object \n",
            " 1   Gender             129 non-null    object \n",
            " 2   Married            129 non-null    object \n",
            " 3   Dependents         127 non-null    object \n",
            " 4   Education          130 non-null    object \n",
            " 5   Self_Employed      123 non-null    object \n",
            " 6   ApplicantIncome    130 non-null    int64  \n",
            " 7   CoapplicantIncome  130 non-null    float64\n",
            " 8   LoanAmount         124 non-null    float64\n",
            " 9   Loan_Amount_Term   129 non-null    float64\n",
            " 10  Credit_History     120 non-null    float64\n",
            " 11  Property_Area      130 non-null    object \n",
            " 12  Loan_Status        130 non-null    object \n",
            "dtypes: float64(4), int64(1), object(8)\n",
            "memory usage: 13.3+ KB\n",
            "None\n",
            "\n",
            "=== Valores únicos por columna ===\n",
            "\n",
            "Loan_ID:\n",
            "Tipo de dato: object\n",
            "Valores únicos: 130\n",
            "Primeros valores únicos: ['LP001002', 'LP001003', 'LP001005', 'LP001013', 'LP001020']\n",
            "\n",
            "Gender:\n",
            "Tipo de dato: object\n",
            "Valores únicos: 2\n",
            "Primeros valores únicos: ['Female', 'Male']\n",
            "\n",
            "Married:\n",
            "Tipo de dato: object\n",
            "Valores únicos: 2\n",
            "Primeros valores únicos: ['No', 'Yes']\n",
            "\n",
            "Dependents:\n",
            "Tipo de dato: object\n",
            "Valores únicos: 4\n",
            "Primeros valores únicos: ['0', '1', '2', '3+']\n",
            "\n",
            "Education:\n",
            "Tipo de dato: object\n",
            "Valores únicos: 2\n",
            "Primeros valores únicos: ['Graduate', 'Not Graduate']\n",
            "\n",
            "Self_Employed:\n",
            "Tipo de dato: object\n",
            "Valores únicos: 2\n",
            "Primeros valores únicos: ['No', 'Yes']\n",
            "\n",
            "ApplicantIncome:\n",
            "Tipo de dato: int64\n",
            "Valores únicos: 119\n",
            "Primeros valores únicos: [150, 1000, 1025, 1378, 1500]\n",
            "\n",
            "CoapplicantIncome:\n",
            "Tipo de dato: float64\n",
            "Valores únicos: 68\n",
            "Primeros valores únicos: [0.0, 240.0, 688.0, 1083.0, 1126.0]\n",
            "\n",
            "LoanAmount:\n",
            "Tipo de dato: float64\n",
            "Valores únicos: 84\n",
            "Primeros valores únicos: [30.0, 40.0, 45.0, 46.0, 48.0]\n",
            "\n",
            "Loan_Amount_Term:\n",
            "Tipo de dato: float64\n",
            "Valores únicos: 7\n",
            "Primeros valores únicos: [36.0, 84.0, 180.0, 240.0, 300.0]\n",
            "\n",
            "Credit_History:\n",
            "Tipo de dato: float64\n",
            "Valores únicos: 2\n",
            "Primeros valores únicos: [0.0, 1.0]\n",
            "\n",
            "Property_Area:\n",
            "Tipo de dato: object\n",
            "Valores únicos: 3\n",
            "Primeros valores únicos: ['Rural', 'Semiurban', 'Urban']\n",
            "\n",
            "Loan_Status:\n",
            "Tipo de dato: object\n",
            "Valores únicos: 2\n",
            "Primeros valores únicos: ['N', 'Y']\n",
            "\n",
            "=== Valores nulos ===\n",
            "Loan_ID               0\n",
            "Gender                1\n",
            "Married               1\n",
            "Dependents            3\n",
            "Education             0\n",
            "Self_Employed         7\n",
            "ApplicantIncome       0\n",
            "CoapplicantIncome     0\n",
            "LoanAmount            6\n",
            "Loan_Amount_Term      1\n",
            "Credit_History       10\n",
            "Property_Area         0\n",
            "Loan_Status           0\n",
            "dtype: int64\n",
            "\n",
            "=== Estadísticas descriptivas ===\n",
            "       ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
            "count       130.000000         130.000000  124.000000        129.000000   \n",
            "mean       5429.507692        1871.676923  144.645161        342.790698   \n",
            "std        4627.710178        3095.300817   81.514844         58.746499   \n",
            "min         150.000000           0.000000   30.000000         36.000000   \n",
            "25%        2962.750000           0.000000   95.750000        360.000000   \n",
            "50%        4001.000000        1280.000000  121.500000        360.000000   \n",
            "75%        6120.500000        2405.750000  170.500000        360.000000   \n",
            "max       39147.000000       20000.000000  500.000000        480.000000   \n",
            "\n",
            "       Credit_History  \n",
            "count      120.000000  \n",
            "mean         0.850000  \n",
            "std          0.358569  \n",
            "min          0.000000  \n",
            "25%          1.000000  \n",
            "50%          1.000000  \n",
            "75%          1.000000  \n",
            "max          1.000000  \n",
            "📊 Distribución de la variable objetivo (Loan_Status):\n",
            "\n",
            "Porcentajes:\n",
            "Clase Y: 69.23%\n",
            "Clase N: 30.77%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "def categorize_features(df):\n",
        "    \"\"\"\n",
        "    Separa las características en numéricas y categóricas.\n",
        "    \"\"\"\n",
        "    # Variables numéricas (montos y edad)\n",
        "    numeric_features = ['ApplicantIncome', 'CoapplicantIncome',\n",
        "        'LoanAmount', 'Loan_Amount_Term', 'Dependents']\n",
        "\n",
        "    # Variables categóricas\n",
        "    categorical_features = [\n",
        "        'Gender', 'Married', 'Education',\n",
        "        'Self_Employed', 'Credit_History', 'Property_Area', 'Loan_Status']\n",
        "\n",
        "    return numeric_features, categorical_features\n",
        "\n",
        "def clean_categorical_data(df):\n",
        "    \"\"\"\n",
        "    Limpia y corrige valores en variables categóricas.\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    # Llenar valores nulos en variables categóricas con 'Unknown'\n",
        "    for col in ['Gender', 'Married', 'Education', 'Self_Employed', 'Property_Area']:\n",
        "        df[col] = df[col].fillna('Unknown')\n",
        "\n",
        "    # Llenar valores nulos en Credit_History con un valor predeterminado (0)\n",
        "    df['Credit_History'] = df['Credit_History'].fillna(0)\n",
        "\n",
        "    return df\n",
        "\n",
        "def preprocess_data(df):\n",
        "    \"\"\"\n",
        "    Realiza el preprocesamiento completo de los datos.\n",
        "    \"\"\"\n",
        "    # 1. Separar features\n",
        "    numeric_features, categorical_features = categorize_features(df)\n",
        "\n",
        "    # 2. Limpiar datos categóricos\n",
        "    df = clean_categorical_data(df)\n",
        "\n",
        "    # 3. Reemplazar \"3+\" por \"3\" en Dependents y convertir a numérico\n",
        "    df['Dependents'] = df['Dependents'].replace('3+', '3').astype(float)\n",
        "\n",
        "    # 4. Estandarizar variables numéricas\n",
        "    scaler = StandardScaler()\n",
        "    df[numeric_features] = scaler.fit_transform(df[numeric_features])\n",
        "\n",
        "    # 5. Codificar variable objetivo Loan_Status (Y -> 1, N -> 0)\n",
        "    df['Loan_Status'] = df['Loan_Status'].map({'Y': 1, 'N': 0})\n",
        "\n",
        "    # 6. Codificar otras Variables\n",
        "    df['Married'] = df['Married'].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "    df['Education'] = df['Education'].map({'Graduate': 1, 'Not Graduate': 0})\n",
        "\n",
        "    df['Self_Employed'] = df['Self_Employed'].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "    # 7. Crear dummies para Property_Area\n",
        "    df = pd.get_dummies(df, columns=['Property_Area'], prefix='', prefix_sep='')\n",
        "    # Convertir solo las columnas dummy a int. Rellenar NaNs con 0 en columnas numéricas.\n",
        "    for col in ['Rural', 'Semiurban', 'Urban']:\n",
        "        df[col] = df[col].fillna(0).astype(int)\n",
        "\n",
        "    # 8. Crear dummies para Gender\n",
        "    df = pd.get_dummies(df, columns=['Gender'], prefix='', prefix_sep='')\n",
        "    # Convertir solo las columnas dummy a int. Rellenar NaNs con 0 en columnas numéricas.\n",
        "    for col in ['Female', 'Male', 'Unknown']:\n",
        "        df[col] = df[col].fillna(0).astype(int)\n",
        "\n",
        "\n",
        "    # 9. Separar features y target\n",
        "    X = df.drop('Loan_Status', axis=1)\n",
        "    y = df['Loan_Status']\n",
        "\n",
        "    # 10. Guardar información del preprocesamiento\n",
        "    preprocessing_info = {\n",
        "        'numeric_features': numeric_features,\n",
        "        'categorical_features': categorical_features,\n",
        "        'scaler': scaler\n",
        "    }\n",
        "\n",
        "    return X, y, preprocessing_info\n",
        "\n",
        "def print_preprocessing_summary(X, y):\n",
        "    \"\"\"\n",
        "    Imprime un resumen del preprocesamiento.\n",
        "    \"\"\"\n",
        "    print(\"\\n=== Resumen del Preprocesamiento ===\")\n",
        "    print(f\"Dimensiones de X: {X.shape}\")\n",
        "\n",
        "    print(\"\\nDistribución de clases:\")\n",
        "    print(pd.Series(y).value_counts(normalize=True).round(3))\n",
        "\n",
        "    print(\"\\nEstadísticas de algunas variables numéricas:\")\n",
        "    print(X.describe().round(2).head())"
      ],
      "metadata": {
        "id": "tDZhSzXaHlQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejecutar el Preprocesamiento\n",
        "\n",
        "# Importar y cargar datos\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# 1. Cargar datos\n",
        "dataset = load_dataset(\"13nishit/LoanApprovalPrediction\", streaming=True)\n",
        "df = pd.DataFrame(list(dataset['train'].shuffle(seed=42).take(10000)))\n",
        "\n",
        "# 2. Aplicar preprocesamiento\n",
        "X, y, preprocessing_info = preprocess_data(df)\n",
        "\n",
        "# 3. Imprimir resumen\n",
        "print_preprocessing_summary(X, y)\n",
        "\n",
        "# 4. Verificar las características procesadas\n",
        "print(\"\\n=== Características procesadas ===\")\n",
        "print(\"\\nCaracterísticas numéricas:\")\n",
        "print(preprocessing_info['numeric_features'])\n",
        "print(\"\\nCaracterísticas categóricas:\")\n",
        "print(preprocessing_info['categorical_features'])\n",
        "\n",
        "# 5. Mostrar información adicional sobre los datos procesados\n",
        "print(\"\\n=== Información adicional ===\")\n",
        "print(f\"Número total de características: {X.shape[1]}\")\n",
        "print(f\"Número total de observaciones: {X.shape[0]}\")\n",
        "print(\"\\nPrimeras columnas del dataset procesado:\")\n",
        "print(X.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWjxLukCHngU",
        "outputId": "b5bee813-3319-4829-9cae-73dde596e496"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Resumen del Preprocesamiento ===\n",
            "Dimensiones de X: (614, 16)\n",
            "\n",
            "Distribución de clases:\n",
            "Loan_Status\n",
            "1    0.687\n",
            "0    0.313\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Estadísticas de algunas variables numéricas:\n",
            "       Married  Dependents  Education  Self_Employed  ApplicantIncome  \\\n",
            "count   611.00      599.00     614.00         582.00           614.00   \n",
            "mean      0.65        0.00       0.78           0.14            -0.00   \n",
            "std       0.48        1.00       0.41           0.35             1.00   \n",
            "min       0.00       -0.75       0.00           0.00            -0.86   \n",
            "25%       0.00       -0.75       1.00           0.00            -0.41   \n",
            "\n",
            "       CoapplicantIncome  LoanAmount  Loan_Amount_Term  Credit_History  \\\n",
            "count             614.00      592.00            600.00          614.00   \n",
            "mean               -0.00        0.00              0.00            0.77   \n",
            "std                 1.00        1.00              1.00            0.42   \n",
            "min                -0.55       -1.61             -5.07            0.00   \n",
            "25%                -0.55       -0.54              0.28            1.00   \n",
            "\n",
            "        Rural  Semiurban   Urban  Female   Male  Unknown  \n",
            "count  614.00     614.00  614.00  614.00  614.0   614.00  \n",
            "mean     0.29       0.38    0.33    0.18    0.8     0.02  \n",
            "std      0.45       0.49    0.47    0.39    0.4     0.14  \n",
            "min      0.00       0.00    0.00    0.00    0.0     0.00  \n",
            "25%      0.00       0.00    0.00    0.00    1.0     0.00  \n",
            "\n",
            "=== Características procesadas ===\n",
            "\n",
            "Características numéricas:\n",
            "['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term', 'Dependents']\n",
            "\n",
            "Características categóricas:\n",
            "['Gender', 'Married', 'Education', 'Self_Employed', 'Credit_History', 'Property_Area', 'Loan_Status']\n",
            "\n",
            "=== Información adicional ===\n",
            "Número total de características: 16\n",
            "Número total de observaciones: 614\n",
            "\n",
            "Primeras columnas del dataset procesado:\n",
            "    Loan_ID  Married  Dependents  Education  Self_Employed  ApplicantIncome  \\\n",
            "0  LP001280      1.0    1.219539          0            0.0        -0.339194   \n",
            "1  LP001345      1.0    1.219539          0            0.0        -0.182740   \n",
            "2  LP001633      1.0    0.233704          1            0.0         0.163259   \n",
            "3  LP002693      1.0    1.219539          1            1.0         0.416860   \n",
            "4  LP002315      1.0    0.233704          1            0.0         0.474527   \n",
            "\n",
            "   CoapplicantIncome  LoanAmount  Loan_Amount_Term  Credit_History  Rural  \\\n",
            "0           0.129539   -0.554431          0.276642             0.0      0   \n",
            "1           0.561501   -0.156840         -2.489775             1.0      0   \n",
            "2           1.925108    0.392771          0.276642             0.0      0   \n",
            "3           1.896379    3.900927          0.276642             1.0      1   \n",
            "4          -0.554487    0.065343         -0.645497             0.0      0   \n",
            "\n",
            "   Semiurban  Urban  Female  Male  Unknown  \n",
            "0          1      0       0     1        0  \n",
            "1          0      1       0     1        0  \n",
            "2          0      1       0     1        0  \n",
            "3          0      0       0     1        0  \n",
            "4          1      0       0     1        0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uD3TKTGVNLdH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos las librerías necesarias\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Cargamos el dataset y lo mezclamos\n",
        "dataset = load_dataset(\"scikit-learn/credit-card-clients\", streaming=True)\n",
        "df = pd.DataFrame(list(dataset['train'].shuffle(seed=42).take(10000)))\n",
        "\n",
        "# 1. Examinamos la información básica del DataFrame\n",
        "print(\"\\n=== Información del DataFrame ===\")\n",
        "print(df.info())\n",
        "\n",
        "# 2. Verificamos los tipos de datos y valores únicos para cada columna\n",
        "print(\"\\n=== Valores únicos por columna ===\")\n",
        "for column in df.columns:\n",
        "    print(f\"\\n{column}:\")\n",
        "    print(f\"Tipo de dato: {df[column].dtype}\")\n",
        "    print(f\"Valores únicos: {df[column].nunique()}\")\n",
        "    print(f\"Primeros valores únicos: {sorted(df[column].unique())[:5]}\")\n",
        "\n",
        "# 3. Verificamos valores nulos\n",
        "print(\"\\n=== Valores nulos ===\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# 4. Estadísticas descriptivas básicas\n",
        "print(\"\\n=== Estadísticas descriptivas ===\")\n",
        "print(df.describe())\n",
        "\n",
        "# 5. Debalance de clases\n",
        "\n",
        "print(\"📊 Distribución de la variable objetivo (default.payment.next.month):\")\n",
        "class_dist = df['default.payment.next.month'].value_counts(normalize=True)\n",
        "print(\"\\nPorcentajes:\")\n",
        "for clase, porcentaje in class_dist.items():\n",
        "    print(f\"Clase {clase}: {porcentaje*100:.2f}%\")\n",
        "\n",
        "# Visualizamos la distribución con un gráfico de barras\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(data=df, x='default.payment.next.month')\n",
        "plt.title('Distribución de Defaults en la muestra')\n",
        "plt.xlabel('Default (0: No, 1: Sí)')\n",
        "plt.ylabel('Cantidad')\n",
        "\n",
        "# Añadimos los valores exactos sobre cada barra\n",
        "for i in plt.gca().containers[0]:\n",
        "    plt.text(i.get_x() + i.get_width()/2,\n",
        "            i.get_height(),\n",
        "            f'{int(i.get_height())}',\n",
        "            ha='center', va='bottom')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Funciones de Preprocesamiento de datos\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "def categorize_features(df):\n",
        "    \"\"\"\n",
        "    Separa las características en numéricas y categóricas.\n",
        "    \"\"\"\n",
        "    # Variables numéricas (montos y edad)\n",
        "    numeric_features = [\n",
        "        'LIMIT_BAL', 'AGE',\n",
        "        'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6',\n",
        "        'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6'\n",
        "    ]\n",
        "\n",
        "    # Variables categóricas\n",
        "    categorical_features = [\n",
        "        'SEX', 'EDUCATION', 'MARRIAGE',\n",
        "        'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6'\n",
        "    ]\n",
        "\n",
        "    return numeric_features, categorical_features\n",
        "\n",
        "def clean_categorical_data(df):\n",
        "    \"\"\"\n",
        "    Limpia y corrige valores en variables categóricas.\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    # Corregir valores en EDUCATION\n",
        "    # 0, 5 y 6 son valores no definidos, los convertimos a 4 (Others)\n",
        "    df['EDUCATION'] = df['EDUCATION'].replace([0, 5, 6], 4)\n",
        "\n",
        "    # Corregir valores en MARRIAGE\n",
        "    # 0 es un valor no definido, lo convertimos a 3 (Others)\n",
        "    df['MARRIAGE'] = df['MARRIAGE'].replace([0], 3)\n",
        "\n",
        "    return df\n",
        "\n",
        "def preprocess_data(df):\n",
        "    \"\"\"\n",
        "    Realiza el preprocesamiento completo de los datos.\n",
        "    \"\"\"\n",
        "    # 1. Separar features\n",
        "    numeric_features, categorical_features = categorize_features(df)\n",
        "\n",
        "    # 2. Limpiar datos categóricos\n",
        "    df = clean_categorical_data(df)\n",
        "\n",
        "    # 3. Estandarizar variables numéricas\n",
        "    scaler = StandardScaler()\n",
        "    df[numeric_features] = scaler.fit_transform(df[numeric_features])\n",
        "\n",
        "    # 4. Codificar variables categóricas\n",
        "    label_encoders = {}\n",
        "    for feature in categorical_features:\n",
        "        label_encoders[feature] = LabelEncoder()\n",
        "        df[feature] = label_encoders[feature].fit_transform(df[feature].astype(str))\n",
        "\n",
        "    # 5. Separar features y target\n",
        "    X = df.drop('default.payment.next.month', axis=1)\n",
        "    y = df['default.payment.next.month']\n",
        "\n",
        "    # 6. Guardar información del preprocesamiento\n",
        "    preprocessing_info = {\n",
        "        'numeric_features': numeric_features,\n",
        "        'categorical_features': categorical_features,\n",
        "        'scaler': scaler,\n",
        "        'label_encoders': label_encoders\n",
        "    }\n",
        "\n",
        "    return X, y, preprocessing_info\n",
        "\n",
        "def print_preprocessing_summary(X, y):\n",
        "    \"\"\"\n",
        "    Imprime un resumen del preprocesamiento.\n",
        "    \"\"\"\n",
        "    print(\"\\n=== Resumen del Preprocesamiento ===\")\n",
        "    print(f\"Dimensiones de X: {X.shape}\")\n",
        "\n",
        "    print(\"\\nDistribución de clases:\")\n",
        "    print(pd.Series(y).value_counts(normalize=True).round(3))\n",
        "\n",
        "    print(\"\\nEstadísticas de algunas variables numéricas:\")\n",
        "    print(X.describe().round(2).head())\n",
        "\n",
        "    # Ejecutar el Preprocesamiento\n",
        "\n",
        "# Importar y cargar datos\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Cargar datos\n",
        "dataset = load_dataset(\"scikit-learn/credit-card-clients\", streaming=True)\n",
        "df = pd.DataFrame(list(dataset['train'].shuffle(seed=42).take(10000)))\n",
        "\n",
        "# 2. Aplicar preprocesamiento\n",
        "X, y, preprocessing_info = preprocess_data(df)\n",
        "\n",
        "# 3. Imprimir resumen\n",
        "print_preprocessing_summary(X, y)\n",
        "\n",
        "# 4. Verificar las características procesadas\n",
        "print(\"\\n=== Características procesadas ===\")\n",
        "print(\"\\nCaracterísticas numéricas:\")\n",
        "print(preprocessing_info['numeric_features'])\n",
        "print(\"\\nCaracterísticas categóricas:\")\n",
        "print(preprocessing_info['categorical_features'])\n",
        "\n",
        "# 5. Mostrar información adicional sobre los datos procesados\n",
        "print(\"\\n=== Información adicional ===\")\n",
        "print(f\"Número total de características: {X.shape[1]}\")\n",
        "print(f\"Número total de observaciones: {X.shape[0]}\")\n",
        "print(\"\\nPrimeras columnas del dataset procesado:\")\n",
        "print(X.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "fx2q6FuONKRk",
        "outputId": "cea57a30-4fac-46e9-8123-8ae57690c033"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "partially initialized module 'pandas' has no attribute '_pandas_parser_CAPI' (most likely due to a circular import)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-ee95e3a7fa4d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Importamos las librerías necesarias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    136\u001b[0m )\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplotting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtseries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_print_versions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/api/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\"\"\" public toolkit API \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m from pandas.api import (\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mindexers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0minterchange\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/api/typing/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# TODO: Can't import Styler without importing jinja2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# from pandas.io.formats.style import Styler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_json\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mJsonReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStataReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/json/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m from pandas.io.json._json import (\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mread_json\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mto_json\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mujson_dumps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mujson_loads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mparse_table_schema\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m )\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreaders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mTYPE_CHECKING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m from pandas.io.parsers.readers import (\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mTextFileReader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mTextParser\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mread_csv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mread_fwf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_libs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_libs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparsers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSTR_NA_VALUES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m from pandas.errors import (\n\u001b[1;32m     34\u001b[0m     \u001b[0mAbstractMethodError\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36minit pandas._libs.parsers\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'pandas' has no attribute '_pandas_parser_CAPI' (most likely due to a circular import)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preparación para el entrenamiento"
      ],
      "metadata": {
        "id": "NJBtgSeOHriZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- PREPARACIÓN PARA EL ENTRENAMIENTO ---\n",
        "\n",
        "# Importamos las bibliotecas necesarias\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.decomposition import PCA\n",
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Fijamos la semilla aleatoria para garantizar reproducibilidad\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "\n",
        "# División estratificada de datos (80% entrenamiento, 20% prueba)\n",
        "# stratify=y asegura que la proporción de las clases se mantenga\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,              # Matriz de características\n",
        "    y,              # Vector objetivo (default/no default)\n",
        "    test_size=0.2,  # 20% para prueba\n",
        "    random_state=RANDOM_STATE,\n",
        "    stratify=y      # Mantiene proporción de clases\n",
        ")\n",
        "\n",
        "# Para XGBoost, necesitamos un conjunto de validación\n",
        "X_train_xgb, X_val_xgb, y_train_xgb, y_val_xgb = train_test_split(\n",
        "    X_train, y_train,\n",
        "    test_size=0.2,\n",
        "    random_state=RANDOM_STATE,\n",
        "    stratify=y_train\n",
        ")\n",
        "\n",
        "# Definición de los modelos a entrenar\n",
        "models = {\n",
        "\n",
        "    # Random Forest\n",
        "    \"RandomForest\": RandomForestClassifier(\n",
        "        n_estimators=100,       # Número de árboles en el bosque\n",
        "        max_depth=None,         # Permite árboles profundos\n",
        "        min_samples_leaf=5,     # Control básico de overfitting\n",
        "        max_features='sqrt',    # Número de features a considerar en cada split\n",
        "        n_jobs=-1,             # Usa todos los núcleos disponibles\n",
        "        random_state=RANDOM_STATE\n",
        "    ),\n",
        "\n",
        "    # XGBoost\n",
        "    \"XGBoost\": xgb.XGBClassifier(\n",
        "        learning_rate=0.1,      # Tamaño de paso en cada iteración\n",
        "        n_estimators=100,       # Número máximo de árboles\n",
        "        max_depth=6,           # Profundidad fija para control de complejidad\n",
        "        early_stopping_rounds=20,# Detiene el entrenamiento si no hay mejora en 20 rondas\n",
        "        min_child_weight=1,     # Control de overfitting similar a min_samples_leaf\n",
        "        subsample=0.8,          # Fracción de muestras para cada árbol\n",
        "        colsample_bytree=0.8,   # Fracción de features para cada árbol\n",
        "        eval_metric=['auc', 'error', 'logloss'],  # Múltiples métricas de evaluación\n",
        "        random_state=RANDOM_STATE,\n",
        "        enable_categorical=False # Deshabilitamos características categóricas\n",
        "    ),\n",
        "\n",
        "    # K-Nearest Neighbors (KNN)\n",
        "    # La elección de k se basa en la raíz cuadrada del número de muestras\n",
        "    \"KNN\": KNeighborsClassifier(\n",
        "        n_neighbors=int(np.sqrt(len(X_train))),  # k basado en regla de la raíz\n",
        "        weights='uniform',       # Todos los vecinos tienen el mismo peso\n",
        "        metric='euclidean'      # Distancia euclidiana para similitud\n",
        "    ),\n",
        "\n",
        "    # Support Vector Machine (SVM)\n",
        "    # Utilizamos kernel RBF para capturar relaciones no lineales\n",
        "    \"SVM\": SVC(\n",
        "        kernel='rbf',           # Tipo de kernel: 'linear', 'poly', 'rbf', 'sigmoid'\n",
        "        C=1.0,                  # Parámetro de margen suave (soft margin):\n",
        "                               # - C grande: margen más estrecho, menos errores permitidos\n",
        "                               # - C pequeño: margen más amplio, más errores permitidos\n",
        "        gamma='scale',          # Coeficiente γ para kernel RBF: exp(-γ||x₁ - x₂||²)\n",
        "                               # 'scale' calcula γ = 1 / (n_features * X.var())\n",
        "        random_state=RANDOM_STATE\n",
        "    ),\n",
        "\n",
        "    # PCA + KNN\n",
        "    # Combinamos reducción de dimensionalidad con clasificación\n",
        "    \"PCA-KNN\": {\n",
        "        'pca': PCA(\n",
        "            n_components=0.95,   # Mantener 95% de la varianza explicada\n",
        "            random_state=RANDOM_STATE\n",
        "        ),\n",
        "        'knn': KNeighborsClassifier(\n",
        "            n_neighbors=5,       # k inicial para clasificación\n",
        "            weights='uniform',\n",
        "            metric='euclidean'\n",
        "        )\n",
        "    }\n",
        "}\n",
        "\n",
        "# Diccionarios para almacenar resultados\n",
        "predictions = {}      # Predicciones binarias (0/1)\n",
        "probabilities = {}    # Probabilidades [0,1]\n",
        "xgb_results = {}     # Para almacenar resultados de evaluación de XGBoost\n",
        "components = {}      # Almacenará componentes principales para PCA\n",
        "\n",
        "# Información sobre la división de datos\n",
        "print(\"=== Información de la División de Datos ===\")\n",
        "print(f\"Dimensiones de X_train: {X_train.shape}\")\n",
        "print(f\"Dimensiones de X_test: {X_test.shape}\")\n",
        "print(f\"Dimensiones de X_val_xgb (para XGBoost): {X_val_xgb.shape}\")\n",
        "print(\"\\nDistribución de clases:\")\n",
        "print(\"\\nConjunto de entrenamiento:\")\n",
        "print(pd.Series(y_train).value_counts(normalize=True).round(3))\n",
        "print(\"\\nConjunto de prueba:\")\n",
        "print(pd.Series(y_test).value_counts(normalize=True).round(3))\n",
        "print(\"\\nConjunto de validación XGBoost:\")\n",
        "print(pd.Series(y_val_xgb).value_counts(normalize=True).round(3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_fgDtRuIBSe",
        "outputId": "47fb6704-556a-4d51-a239-840e2afa7937"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Información de la División de Datos ===\n",
            "Dimensiones de X_train: (8000, 24)\n",
            "Dimensiones de X_test: (2000, 24)\n",
            "Dimensiones de X_val_xgb (para XGBoost): (1600, 24)\n",
            "\n",
            "Distribución de clases:\n",
            "\n",
            "Conjunto de entrenamiento:\n",
            "default.payment.next.month\n",
            "0    0.776\n",
            "1    0.224\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Conjunto de prueba:\n",
            "default.payment.next.month\n",
            "0    0.776\n",
            "1    0.224\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Conjunto de validación XGBoost:\n",
            "default.payment.next.month\n",
            "0    0.776\n",
            "1    0.224\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Iniciar entrenamiento"
      ],
      "metadata": {
        "id": "iSh1pwgDPj_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- ENTRENAMIENTO DE MODELOS ---\n",
        "\n",
        "def print_model_info(name, model, X_train):\n",
        "    \"\"\"\n",
        "    Imprime información relevante según el tipo de modelo\n",
        "    \"\"\"\n",
        "    print(f\"\\nInformación para {name}:\")\n",
        "\n",
        "    if hasattr(model, 'feature_importances_'):\n",
        "        # Para modelos basados en árboles que tienen importancia de características\n",
        "        importances = pd.DataFrame({\n",
        "            'Feature': X_train.columns,\n",
        "            'Importance': model.feature_importances_\n",
        "        }).sort_values('Importance', ascending=False)\n",
        "\n",
        "        print(\"\\nTop 5 características más importantes:\")\n",
        "        print(importances.head())\n",
        "        print(\"\\nTop 5 características menos importantes:\")\n",
        "        print(importances.tail())\n",
        "\n",
        "    # Información específica para cada tipo de modelo\n",
        "    if name == \"RandomForest\":\n",
        "        print(f\"\\nNúmero de árboles: {model.n_estimators}\")\n",
        "        print(f\"Máxima profundidad: {model.max_depth if model.max_depth else 'No limitada'}\")\n",
        "        print(f\"Features por split: {model.max_features}\")\n",
        "    elif name == \"XGBoost\":\n",
        "        print(\"\\nMejor iteración: \", model.best_iteration if hasattr(model, 'best_iteration') else None)\n",
        "        print(f\"Tasa de aprendizaje: {model.learning_rate}\")\n",
        "        print(f\"Número de estimadores: {model.n_estimators}\")\n",
        "    elif name == \"KNN\":\n",
        "        print(f\"\\nNúmero de vecinos (k): {model.n_neighbors}\")\n",
        "        print(f\"Métrica de distancia: {model.metric}\")\n",
        "    elif name == \"SVM\":\n",
        "        print(f\"\\nTipo de kernel: {model.kernel}\")\n",
        "        print(f\"Parámetro C (regularización): {model.C}\")\n",
        "        print(f\"Parámetro gamma: {model.gamma}\")\n",
        "    elif name == \"PCA-KNN\":\n",
        "        print(f\"\\nNúmero de componentes principales: {model['pca'].n_components_}\")\n",
        "        print(f\"Varianza explicada acumulada: {np.sum(model['pca'].explained_variance_ratio_):.2f}\")\n",
        "        print(f\"Número de vecinos (k): {model['knn'].n_neighbors}\")\n",
        "        print(f\"Métrica de distancia: {model['knn'].metric}\")\n",
        "\n",
        "# Iteramos sobre cada modelo para entrenamiento y predicciones\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n=== Entrenando modelo: {name} ===\")\n",
        "\n",
        "    # Entrenamiento del modelo\n",
        "    if name == \"XGBoost\":\n",
        "        # Usamos los conjuntos de validación previamente creados\n",
        "        model.fit(\n",
        "            X_train_xgb, y_train_xgb,\n",
        "            eval_set=[(X_train_xgb, y_train_xgb), (X_val_xgb, y_val_xgb)],\n",
        "            verbose=False\n",
        "        )\n",
        "\n",
        "        predictions[name] = model.predict(X_test)\n",
        "        probabilities[name] = model.predict_proba(X_test)[:, 1]\n",
        "    elif name == \"PCA-KNN\":\n",
        "        # Aplicamos PCA primero\n",
        "        components[name] = model['pca'].fit_transform(X_train)\n",
        "        model['knn'].fit(components[name], y_train)\n",
        "\n",
        "        # Transformamos el conjunto de prueba con el PCA ajustado\n",
        "        X_test_pca = model['pca'].transform(X_test)\n",
        "        predictions[name] = model['knn'].predict(X_test_pca)\n",
        "        probabilities[name] = model['knn'].predict_proba(X_test_pca)[:, 1]\n",
        "    elif name == \"SVM\":\n",
        "        # Configuramos probability=True para habilitar predict_proba\n",
        "        model.set_params(probability=True)\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions[name] = model.predict(X_test)\n",
        "        probabilities[name] = model.predict_proba(X_test)[:, 1]\n",
        "    else:\n",
        "        # Para RandomForest y KNN\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions[name] = model.predict(X_test)\n",
        "        probabilities[name] = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Mostrar información del modelo\n",
        "    print_model_info(name, model, X_train)\n",
        "\n",
        "# Calculamos y mostramos el tiempo de ejecución promedio para predicciones\n",
        "import time\n",
        "\n",
        "print(\"\\n=== Evaluación de Tiempo de Predicción ===\")\n",
        "for name, model in models.items():\n",
        "    times = []\n",
        "    for _ in range(100):  # 100 predicciones para promedio estable\n",
        "        start_time = time.time()\n",
        "        if name == \"PCA-KNN\":\n",
        "            X_test_pca = model['pca'].transform(X_test[:100])\n",
        "            model['knn'].predict(X_test_pca)\n",
        "        else:\n",
        "            model.predict(X_test[:100])\n",
        "        times.append(time.time() - start_time)\n",
        "\n",
        "    print(f\"\\n{name}:\")\n",
        "    print(f\"Tiempo promedio de predicción: {np.mean(times)*1000:.2f} ms\")\n",
        "    print(f\"Desviación estándar: {np.std(times)*1000:.2f} ms\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z14LMNu4Pos9",
        "outputId": "a5659a7e-3906-43ef-bdcd-54f9a81cb7c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Entrenando modelo: RandomForest ===\n",
            "\n",
            "Información para RandomForest:\n",
            "\n",
            "Top 5 características más importantes:\n",
            "      Feature  Importance\n",
            "6       PAY_0    0.129697\n",
            "7       PAY_2    0.061898\n",
            "0          ID    0.057274\n",
            "12  BILL_AMT1    0.048693\n",
            "1   LIMIT_BAL    0.046750\n",
            "\n",
            "Top 5 características menos importantes:\n",
            "      Feature  Importance\n",
            "10      PAY_5    0.028087\n",
            "11      PAY_6    0.019895\n",
            "3   EDUCATION    0.011421\n",
            "2         SEX    0.008520\n",
            "4    MARRIAGE    0.008219\n",
            "\n",
            "Número de árboles: 100\n",
            "Máxima profundidad: No limitada\n",
            "Features por split: sqrt\n",
            "\n",
            "=== Entrenando modelo: XGBoost ===\n",
            "\n",
            "Información para XGBoost:\n",
            "\n",
            "Top 5 características más importantes:\n",
            "   Feature  Importance\n",
            "6    PAY_0    0.304871\n",
            "8    PAY_3    0.066769\n",
            "11   PAY_6    0.038851\n",
            "10   PAY_5    0.038670\n",
            "7    PAY_2    0.037068\n",
            "\n",
            "Top 5 características menos importantes:\n",
            "     Feature  Importance\n",
            "0         ID    0.023862\n",
            "5        AGE    0.023066\n",
            "4   MARRIAGE    0.022867\n",
            "3  EDUCATION    0.021780\n",
            "2        SEX    0.021650\n",
            "\n",
            "Mejor iteración:  31\n",
            "Tasa de aprendizaje: 0.1\n",
            "Número de estimadores: 100\n",
            "\n",
            "=== Entrenando modelo: KNN ===\n",
            "\n",
            "Información para KNN:\n",
            "\n",
            "Número de vecinos (k): 89\n",
            "Métrica de distancia: euclidean\n",
            "\n",
            "=== Entrenando modelo: SVM ===\n",
            "\n",
            "Información para SVM:\n",
            "\n",
            "Tipo de kernel: rbf\n",
            "Parámetro C (regularización): 1.0\n",
            "Parámetro gamma: scale\n",
            "\n",
            "=== Entrenando modelo: PCA-KNN ===\n",
            "\n",
            "Información para PCA-KNN:\n",
            "\n",
            "Número de componentes principales: 1\n",
            "Varianza explicada acumulada: 1.00\n",
            "Número de vecinos (k): 5\n",
            "Métrica de distancia: euclidean\n",
            "\n",
            "=== Evaluación de Tiempo de Predicción ===\n",
            "\n",
            "RandomForest:\n",
            "Tiempo promedio de predicción: 38.41 ms\n",
            "Desviación estándar: 3.81 ms\n",
            "\n",
            "XGBoost:\n",
            "Tiempo promedio de predicción: 8.00 ms\n",
            "Desviación estándar: 0.94 ms\n",
            "\n",
            "KNN:\n",
            "Tiempo promedio de predicción: 17.91 ms\n",
            "Desviación estándar: 1.29 ms\n",
            "\n",
            "SVM:\n",
            "Tiempo promedio de predicción: 27.50 ms\n",
            "Desviación estándar: 2.25 ms\n",
            "\n",
            "PCA-KNN:\n",
            "Tiempo promedio de predicción: 8.86 ms\n",
            "Desviación estándar: 1.53 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##MÉTRICAS DE EVALUACIÓN DE MODELOS DE RIESGO CREDITICIO"
      ],
      "metadata": {
        "id": "VmHE5_YZ5QyY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Evaluación y Métricas Tradicionales ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report, accuracy_score,\n",
        "    precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
        ")\n",
        "\n",
        "class ModelEvaluator:\n",
        "    def __init__(self, y_true, predictions, probabilities):\n",
        "        \"\"\"\n",
        "        Inicializa el evaluador con los datos necesarios.\n",
        "\n",
        "        Parámetros:\n",
        "        -----------\n",
        "        y_true: array-like\n",
        "            Etiquetas verdaderas\n",
        "        predictions: dict\n",
        "            Diccionario con predicciones de cada modelo\n",
        "        probabilities: dict\n",
        "            Diccionario con probabilidades de cada modelo\n",
        "        \"\"\"\n",
        "        # Asegurar que los datos estén en el formato correcto\n",
        "        self.y_true = np.array(y_true)\n",
        "        self.predictions = {k: np.array(v) for k, v in predictions.items()}\n",
        "        self.probabilities = {k: np.array(v) for k, v in probabilities.items()}\n",
        "        self.colors = [\"#EDF2FB\", \"#ABC4FF\"]\n",
        "\n",
        "    def create_metrics_table(self):\n",
        "        \"\"\"\n",
        "        Crea una tabla comparativa con las métricas de todos los modelos.\n",
        "        \"\"\"\n",
        "        metrics = []\n",
        "        for name, pred in self.predictions.items():\n",
        "            try:\n",
        "                metric_dict = {\n",
        "                    'Modelo': name,\n",
        "                    'Accuracy': accuracy_score(self.y_true, pred),\n",
        "                    'Precision': precision_score(self.y_true, pred, zero_division=0),\n",
        "                    'Recall': recall_score(self.y_true, pred),\n",
        "                    'F1-Score': f1_score(self.y_true, pred),\n",
        "                    'AUC-ROC': roc_auc_score(self.y_true, self.probabilities[name])\n",
        "                }\n",
        "            except Exception as e:\n",
        "                print(f\"Error calculando métricas para {name}: {str(e)}\")\n",
        "                metric_dict = {\n",
        "                    'Modelo': name,\n",
        "                    'Accuracy': 'Error',\n",
        "                    'Precision': 'Error',\n",
        "                    'Recall': 'Error',\n",
        "                    'F1-Score': 'Error',\n",
        "                    'AUC-ROC': 'Error'\n",
        "                }\n",
        "\n",
        "            metrics.append(metric_dict)\n",
        "\n",
        "        df_metrics = pd.DataFrame(metrics)\n",
        "\n",
        "        # Formatear las columnas numéricas\n",
        "        numeric_columns = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC-ROC']\n",
        "\n",
        "        for col in numeric_columns:\n",
        "            if col in df_metrics.columns:\n",
        "                df_metrics[col] = pd.to_numeric(df_metrics[col], errors='ignore')\n",
        "                df_metrics[col] = df_metrics[col].apply(\n",
        "                    lambda x: f\"{x:.4f}\" if isinstance(x, (int, float)) else x\n",
        "                )\n",
        "\n",
        "        return df_metrics\n",
        "\n",
        "    def plot_confusion_matrices(self):\n",
        "        \"\"\"\n",
        "        Visualiza las matrices de confusión para modelos de clasificación.\n",
        "        \"\"\"\n",
        "        n_models = len(self.predictions)\n",
        "        fig, axes = plt.subplots(1, n_models, figsize=(5*n_models, 4))\n",
        "        if n_models == 1:\n",
        "            axes = [axes]\n",
        "\n",
        "        cmap = sns.color_palette(self.colors, as_cmap=True)\n",
        "\n",
        "        for idx, (name, y_pred) in enumerate(self.predictions.items()):\n",
        "            try:\n",
        "                cm = confusion_matrix(self.y_true, y_pred)\n",
        "                sns.heatmap(\n",
        "                    cm,\n",
        "                    annot=True,\n",
        "                    fmt='d',\n",
        "                    ax=axes[idx],\n",
        "                    cmap=cmap,\n",
        "                    cbar=False,\n",
        "                    linewidths=1,\n",
        "                    linecolor='gray',\n",
        "                    square=True\n",
        "                )\n",
        "                axes[idx].set_title(f'Matriz de Confusión\\n{name}')\n",
        "                axes[idx].set_xlabel('Predicción')\n",
        "                axes[idx].set_ylabel('Valor Real')\n",
        "                axes[idx].set_xticklabels(['No Default', 'Default'])\n",
        "                axes[idx].set_yticklabels(['No Default', 'Default'], rotation=0)\n",
        "            except Exception as e:\n",
        "                print(f\"Error al crear matriz de confusión para {name}: {str(e)}\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        return fig\n",
        "\n",
        "    def plot_roc_curves(self):\n",
        "        \"\"\"\n",
        "        Visualiza las curvas ROC para modelos de clasificación.\n",
        "        \"\"\"\n",
        "        fig, ax = plt.subplots(figsize=(10, 6))\n",
        "        colors = ['blue', 'orange', 'green', 'red']\n",
        "\n",
        "        for (name, probs), color in zip(self.probabilities.items(), colors):\n",
        "            try:\n",
        "                fpr, tpr, _ = roc_curve(self.y_true, probs)\n",
        "                auc = roc_auc_score(self.y_true, probs)\n",
        "                ax.plot(fpr, tpr, color=color, lw=2,\n",
        "                       label=f'{name} (AUC = {auc:.3f})')\n",
        "            except Exception as e:\n",
        "                print(f\"Error al crear curva ROC para {name}: {str(e)}\")\n",
        "\n",
        "        ax.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
        "        ax.set(xlim=[0.0, 1.0], ylim=[0.0, 1.05],\n",
        "               xlabel='Tasa de Falsos Positivos',\n",
        "               ylabel='Tasa de Verdaderos Positivos',\n",
        "               title='Curvas ROC para los Modelos de Predicción de Default')\n",
        "        ax.legend(loc=\"lower right\")\n",
        "        ax.grid(True, alpha=0.3)\n",
        "\n",
        "        return fig\n",
        "\n",
        "    def evaluate_all(self):\n",
        "        \"\"\"\n",
        "        Ejecuta todas las evaluaciones y muestra los resultados.\n",
        "        \"\"\"\n",
        "        # Tabla de métricas\n",
        "        try:\n",
        "            metrics_table = self.create_metrics_table()\n",
        "            print(\"\\n=== Tabla Comparativa de Métricas ===\")\n",
        "            print(metrics_table.to_string(index=False))\n",
        "        except Exception as e:\n",
        "            print(f\"Error al crear tabla de métricas: {str(e)}\")\n",
        "\n",
        "        # Matrices de confusión\n",
        "        print(\"\\n=== Matrices de Confusión ===\")\n",
        "        cm_fig = self.plot_confusion_matrices()\n",
        "        if cm_fig:\n",
        "            plt.show()\n",
        "\n",
        "        # Curvas ROC\n",
        "        print(\"\\n=== Curvas ROC ===\")\n",
        "        roc_fig = self.plot_roc_curves()\n",
        "        if roc_fig:\n",
        "            plt.show()\n",
        "\n",
        "def evaluar_modelos(y_test, predictions, probabilities):\n",
        "    \"\"\"\n",
        "    Función auxiliar para ejecutar la evaluación simplificada de modelos.\n",
        "\n",
        "    Parámetros:\n",
        "    -----------\n",
        "    y_test : array-like\n",
        "        Etiquetas verdaderas\n",
        "    predictions : dict\n",
        "        Diccionario con predicciones de cada modelo\n",
        "    probabilities : dict\n",
        "        Diccionario con probabilidades de cada modelo\n",
        "    \"\"\"\n",
        "    evaluator = ModelEvaluator(y_test, predictions, probabilities)\n",
        "    evaluator.evaluate_all()\n",
        "\n",
        "# Ejemplo de uso:\n",
        "evaluar_modelos(y_test, predictions, probabilities)"
      ],
      "metadata": {
        "id": "FzkNjCzWC89h",
        "outputId": "4039cc0d-d378-4eb8-fbc1-23a8db19be60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1fd7cd48a7a8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# --- Evaluación y Métricas Tradicionales ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_init\u001b[0m  \u001b[0;31m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m from pandas.core.api import (\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0;31m# dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mArrowDtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFlags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m from pandas.core.groupby import (\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mGrouper\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mNamedAgg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/groupby/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m from pandas.core.groupby.generic import (\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mDataFrameGroupBy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mNamedAgg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mSeriesGroupBy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m )\n\u001b[1;32m     67\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m from pandas.core.groupby import (\n\u001b[1;32m     70\u001b[0m     \u001b[0mbase\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0msanitize_masked_array\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m )\n\u001b[0;32m--> 149\u001b[0;31m from pandas.core.generic import (\n\u001b[0m\u001b[1;32m    150\u001b[0m     \u001b[0mNDFrame\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0mmake_doc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    150\u001b[0m )\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m from pandas.core import (\n\u001b[0m\u001b[1;32m    153\u001b[0m     \u001b[0malgorithms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0malgos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0marraylike\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mlength_of_indexer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m )\n\u001b[0;32m---> 79\u001b[0;31m from pandas.core.indexes.api import (\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mMultiIndex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m )\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategory\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCategoricalIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetimes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDatetimeIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterval\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIntervalIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/datetimes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mmaybe_extract_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m )\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetimelike\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDatetimeTimedeltaMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextension\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minherit_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/datetimelike.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     67\u001b[0m )\n\u001b[1;32m     68\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextension\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNDArrayBackedExtensionIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRangeIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimedeltas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_timedelta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mRangeIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \"\"\"\n\u001b[1;32m     68\u001b[0m     \u001b[0mImmutable\u001b[0m \u001b[0mIndex\u001b[0m \u001b[0mimplementing\u001b[0m \u001b[0ma\u001b[0m \u001b[0mmonotonic\u001b[0m \u001b[0minteger\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mRangeIndex\u001b[0;34m()\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m     @deprecate_nonkeyword_arguments(\n\u001b[0m\u001b[1;32m    596\u001b[0m         \u001b[0mversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"3.0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowed_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"self\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sort_values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mdecorate\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mold_sig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mallowed_args\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/inspect.py\u001b[0m in \u001b[0;36msignature\u001b[0;34m(obj, follow_wrapped, globals, locals, eval_str)\u001b[0m\n\u001b[1;32m   3261\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_wrapped\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3262\u001b[0m     \u001b[0;34m\"\"\"Get a signature object for the passed callable.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3263\u001b[0;31m     return Signature.from_callable(obj, follow_wrapped=follow_wrapped,\n\u001b[0m\u001b[1;32m   3264\u001b[0m                                    globals=globals, locals=locals, eval_str=eval_str)\n\u001b[1;32m   3265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/inspect.py\u001b[0m in \u001b[0;36mfrom_callable\u001b[0;34m(cls, obj, follow_wrapped, globals, locals, eval_str)\u001b[0m\n\u001b[1;32m   3009\u001b[0m                       follow_wrapped=True, globals=None, locals=None, eval_str=False):\n\u001b[1;32m   3010\u001b[0m         \u001b[0;34m\"\"\"Constructs Signature for the given callable object.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3011\u001b[0;31m         return _signature_from_callable(obj, sigcls=cls,\n\u001b[0m\u001b[1;32m   3012\u001b[0m                                         \u001b[0mfollow_wrapper_chains\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_wrapped\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3013\u001b[0m                                         globals=globals, locals=locals, eval_str=eval_str)\n",
            "\u001b[0;32m/usr/lib/python3.11/inspect.py\u001b[0m in \u001b[0;36m_signature_from_callable\u001b[0;34m(obj, follow_wrapper_chains, skip_bound_arg, globals, locals, eval_str, sigcls)\u001b[0m\n\u001b[1;32m   2521\u001b[0m         \u001b[0;31m# If it's a pure Python function, or an object that is duck type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2522\u001b[0m         \u001b[0;31m# of a Python function (Cython functions, for instance), then:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2523\u001b[0;31m         return _signature_from_function(sigcls, obj,\n\u001b[0m\u001b[1;32m   2524\u001b[0m                                         \u001b[0mskip_bound_arg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_bound_arg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2525\u001b[0m                                         globals=globals, locals=locals, eval_str=eval_str)\n",
            "\u001b[0;32m/usr/lib/python3.11/inspect.py\u001b[0m in \u001b[0;36m_signature_from_function\u001b[0;34m(cls, func, skip_bound_arg, globals, locals, eval_str)\u001b[0m\n\u001b[1;32m   2374\u001b[0m         \u001b[0mkind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_POSITIONAL_ONLY\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mposonly_left\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_POSITIONAL_OR_KEYWORD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2375\u001b[0m         \u001b[0mannotation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_empty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2376\u001b[0;31m         parameters.append(Parameter(name, annotation=annotation,\n\u001b[0m\u001b[1;32m   2377\u001b[0m                                     kind=kind))\n\u001b[1;32m   2378\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mposonly_left\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/inspect.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, kind, default, annotation)\u001b[0m\n\u001b[1;32m   2667\u001b[0m     \u001b[0mempty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2669\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_empty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_empty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2670\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2671\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ParameterKind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ee3bBvHKC-pX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}