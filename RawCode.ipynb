{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicolassmarti/HE2_IA_P1/blob/main/RawCode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Instalaci√≥n de librerias"
      ],
      "metadata": {
        "id": "BFi0uihGGzr-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalaci√≥n silenciosa de librer√≠as\n",
        "!pip install -q pandas\n",
        "!pip install -q numpy\n",
        "!pip install -q scipy\n",
        "!pip install -q matplotlib\n",
        "!pip install -q seaborn\n",
        "!pip install -q plotly\n",
        "!pip install -q yellowbrick\n",
        "!pip install -q scikit-learn\n",
        "!pip install -q imbalanced-learn\n",
        "!pip install -q tqdm\n",
        "!pip install -q joblib\n",
        "!pip install -q huggingface_hub\n",
        "!pip install -q datasets\n",
        "!pip install -q fsspec==2024.10.0\n",
        "\n",
        "SEED = 2025\n"
      ],
      "metadata": {
        "id": "6HUYPpcwGhsA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Cargar base de datos"
      ],
      "metadata": {
        "id": "pJ7X-aYbGixG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "J7AknCFS-Cip",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "d6f5f45b-5737-4deb-dd01-a87feb817df4"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "partially initialized module 'pandas' has no attribute '_pandas_parser_CAPI' (most likely due to a circular import)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-a3adc7677bd0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Importamos las librer√≠as necesarias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    136\u001b[0m )\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplotting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtseries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_print_versions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/api/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\"\"\" public toolkit API \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m from pandas.api import (\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mindexers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0minterchange\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/api/typing/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# TODO: Can't import Styler without importing jinja2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# from pandas.io.formats.style import Styler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_json\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mJsonReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStataReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/json/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m from pandas.io.json._json import (\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mread_json\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mto_json\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mujson_dumps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mujson_loads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mparse_table_schema\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m )\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreaders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mTYPE_CHECKING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m from pandas.io.parsers.readers import (\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mTextFileReader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mTextParser\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mread_csv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mread_fwf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_libs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_libs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparsers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSTR_NA_VALUES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m from pandas.errors import (\n\u001b[1;32m     34\u001b[0m     \u001b[0mAbstractMethodError\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36minit pandas._libs.parsers\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'pandas' has no attribute '_pandas_parser_CAPI' (most likely due to a circular import)"
          ]
        }
      ],
      "source": [
        "# Importamos las librer√≠as necesarias\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Cargamos el dataset y lo mezclamos\n",
        "dataset = load_dataset(\"13nishit/LoanApprovalPrediction\")\n",
        "print(dataset)\n",
        "\n",
        "dataset = load_dataset(\"13nishit/LoanApprovalPrediction\", streaming=True)\n",
        "df = pd.DataFrame(list(dataset['train'].shuffle(seed=2025).take(130)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Procesamiento de datos"
      ],
      "metadata": {
        "id": "Zjn8gr5nHFhp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Examinamos la informaci√≥n b√°sica del DataFrame\n",
        "print(\"\\n=== Informaci√≥n del DataFrame ===\")\n",
        "print(df.info())\n",
        "\n",
        "# 2. Verificamos los tipos de datos y valores √∫nicos para cada columna\n",
        "print(\"\\n=== Valores √∫nicos por columna ===\")\n",
        "for column in df.columns:\n",
        "    print(f\"\\n{column}:\")\n",
        "    print(f\"Tipo de dato: {df[column].dtype}\")\n",
        "    print(f\"Valores √∫nicos: {df[column].nunique()}\")\n",
        "\n",
        "# Filtrar valores nulos antes de ordenar\n",
        "    unique_values = [val for val in df[column].unique() if pd.notna(val)]\n",
        "\n",
        "    # Ordenar solo si hay valores no nulos\n",
        "    if unique_values:\n",
        "        print(f\"Primeros valores √∫nicos: {sorted(unique_values)[:5]}\")\n",
        "    else:\n",
        "        print(\"Primeros valores √∫nicos: No hay valores v√°lidos\")\n",
        "\n",
        "# 3. Verificamos valores nulos\n",
        "print(\"\\n=== Valores nulos ===\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# 4. Estad√≠sticas descriptivas b√°sicas\n",
        "print(\"\\n=== Estad√≠sticas descriptivas ===\")\n",
        "print(df.describe())\n",
        "\n",
        "# 5. Debalance de clases\n",
        "\n",
        "print(\"üìä Distribuci√≥n de la variable objetivo (Loan_Status):\")\n",
        "class_dist = df['Loan_Status'].value_counts(normalize=True)\n",
        "print(\"\\nPorcentajes:\")\n",
        "for clase, porcentaje in class_dist.items():\n",
        "    print(f\"Clase {clase}: {porcentaje*100:.2f}%\")\n",
        "\n",
        "# Visualizamos la distribuci√≥n con un gr√°fico de barras\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(data=df, x='Loan_Status')\n",
        "plt.title('Distribuci√≥n de Defaults en la muestra')\n",
        "plt.xlabel('Default (N: No, Y: S√≠)')\n",
        "plt.ylabel('Cantidad')\n",
        "\n",
        "# A√±adimos los valores exactos sobre cada barra\n",
        "for i in plt.gca().containers[0]:\n",
        "    plt.text(i.get_x() + i.get_width()/2,\n",
        "            i.get_height(),\n",
        "            f'{int(i.get_height())}',\n",
        "            ha='center', va='bottom')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xZBxVIyrGlQM",
        "outputId": "ef580bd5-aba9-4fdc-b182-ae388a19d61d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Informaci√≥n del DataFrame ===\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 130 entries, 0 to 129\n",
            "Data columns (total 13 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   Loan_ID            130 non-null    object \n",
            " 1   Gender             129 non-null    object \n",
            " 2   Married            129 non-null    object \n",
            " 3   Dependents         127 non-null    object \n",
            " 4   Education          130 non-null    object \n",
            " 5   Self_Employed      123 non-null    object \n",
            " 6   ApplicantIncome    130 non-null    int64  \n",
            " 7   CoapplicantIncome  130 non-null    float64\n",
            " 8   LoanAmount         124 non-null    float64\n",
            " 9   Loan_Amount_Term   129 non-null    float64\n",
            " 10  Credit_History     120 non-null    float64\n",
            " 11  Property_Area      130 non-null    object \n",
            " 12  Loan_Status        130 non-null    object \n",
            "dtypes: float64(4), int64(1), object(8)\n",
            "memory usage: 13.3+ KB\n",
            "None\n",
            "\n",
            "=== Valores √∫nicos por columna ===\n",
            "\n",
            "Loan_ID:\n",
            "Tipo de dato: object\n",
            "Valores √∫nicos: 130\n",
            "Primeros valores √∫nicos: ['LP001002', 'LP001003', 'LP001005', 'LP001013', 'LP001020']\n",
            "\n",
            "Gender:\n",
            "Tipo de dato: object\n",
            "Valores √∫nicos: 2\n",
            "Primeros valores √∫nicos: ['Female', 'Male']\n",
            "\n",
            "Married:\n",
            "Tipo de dato: object\n",
            "Valores √∫nicos: 2\n",
            "Primeros valores √∫nicos: ['No', 'Yes']\n",
            "\n",
            "Dependents:\n",
            "Tipo de dato: object\n",
            "Valores √∫nicos: 4\n",
            "Primeros valores √∫nicos: ['0', '1', '2', '3+']\n",
            "\n",
            "Education:\n",
            "Tipo de dato: object\n",
            "Valores √∫nicos: 2\n",
            "Primeros valores √∫nicos: ['Graduate', 'Not Graduate']\n",
            "\n",
            "Self_Employed:\n",
            "Tipo de dato: object\n",
            "Valores √∫nicos: 2\n",
            "Primeros valores √∫nicos: ['No', 'Yes']\n",
            "\n",
            "ApplicantIncome:\n",
            "Tipo de dato: int64\n",
            "Valores √∫nicos: 119\n",
            "Primeros valores √∫nicos: [150, 1000, 1025, 1378, 1500]\n",
            "\n",
            "CoapplicantIncome:\n",
            "Tipo de dato: float64\n",
            "Valores √∫nicos: 68\n",
            "Primeros valores √∫nicos: [0.0, 240.0, 688.0, 1083.0, 1126.0]\n",
            "\n",
            "LoanAmount:\n",
            "Tipo de dato: float64\n",
            "Valores √∫nicos: 84\n",
            "Primeros valores √∫nicos: [30.0, 40.0, 45.0, 46.0, 48.0]\n",
            "\n",
            "Loan_Amount_Term:\n",
            "Tipo de dato: float64\n",
            "Valores √∫nicos: 7\n",
            "Primeros valores √∫nicos: [36.0, 84.0, 180.0, 240.0, 300.0]\n",
            "\n",
            "Credit_History:\n",
            "Tipo de dato: float64\n",
            "Valores √∫nicos: 2\n",
            "Primeros valores √∫nicos: [0.0, 1.0]\n",
            "\n",
            "Property_Area:\n",
            "Tipo de dato: object\n",
            "Valores √∫nicos: 3\n",
            "Primeros valores √∫nicos: ['Rural', 'Semiurban', 'Urban']\n",
            "\n",
            "Loan_Status:\n",
            "Tipo de dato: object\n",
            "Valores √∫nicos: 2\n",
            "Primeros valores √∫nicos: ['N', 'Y']\n",
            "\n",
            "=== Valores nulos ===\n",
            "Loan_ID               0\n",
            "Gender                1\n",
            "Married               1\n",
            "Dependents            3\n",
            "Education             0\n",
            "Self_Employed         7\n",
            "ApplicantIncome       0\n",
            "CoapplicantIncome     0\n",
            "LoanAmount            6\n",
            "Loan_Amount_Term      1\n",
            "Credit_History       10\n",
            "Property_Area         0\n",
            "Loan_Status           0\n",
            "dtype: int64\n",
            "\n",
            "=== Estad√≠sticas descriptivas ===\n",
            "       ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
            "count       130.000000         130.000000  124.000000        129.000000   \n",
            "mean       5429.507692        1871.676923  144.645161        342.790698   \n",
            "std        4627.710178        3095.300817   81.514844         58.746499   \n",
            "min         150.000000           0.000000   30.000000         36.000000   \n",
            "25%        2962.750000           0.000000   95.750000        360.000000   \n",
            "50%        4001.000000        1280.000000  121.500000        360.000000   \n",
            "75%        6120.500000        2405.750000  170.500000        360.000000   \n",
            "max       39147.000000       20000.000000  500.000000        480.000000   \n",
            "\n",
            "       Credit_History  \n",
            "count      120.000000  \n",
            "mean         0.850000  \n",
            "std          0.358569  \n",
            "min          0.000000  \n",
            "25%          1.000000  \n",
            "50%          1.000000  \n",
            "75%          1.000000  \n",
            "max          1.000000  \n",
            "üìä Distribuci√≥n de la variable objetivo (Loan_Status):\n",
            "\n",
            "Porcentajes:\n",
            "Clase Y: 69.23%\n",
            "Clase N: 30.77%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "def categorize_features(df):\n",
        "    \"\"\"\n",
        "    Separa las caracter√≠sticas en num√©ricas y categ√≥ricas.\n",
        "    \"\"\"\n",
        "    # Variables num√©ricas (montos y edad)\n",
        "    numeric_features = ['ApplicantIncome', 'CoapplicantIncome',\n",
        "        'LoanAmount', 'Loan_Amount_Term', 'Dependents']\n",
        "\n",
        "    # Variables categ√≥ricas\n",
        "    categorical_features = [\n",
        "        'Gender', 'Married', 'Education',\n",
        "        'Self_Employed', 'Credit_History', 'Property_Area', 'Loan_Status']\n",
        "\n",
        "    return numeric_features, categorical_features\n",
        "\n",
        "def clean_categorical_data(df):\n",
        "    \"\"\"\n",
        "    Limpia y corrige valores en variables categ√≥ricas.\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    # Llenar valores nulos en variables categ√≥ricas con 'Unknown'\n",
        "    for col in ['Gender', 'Married', 'Education', 'Self_Employed', 'Property_Area']:\n",
        "        df[col] = df[col].fillna('Unknown')\n",
        "\n",
        "    # Llenar valores nulos en Credit_History con un valor predeterminado (0)\n",
        "    df['Credit_History'] = df['Credit_History'].fillna(0)\n",
        "\n",
        "    return df\n",
        "\n",
        "def preprocess_data(df):\n",
        "    \"\"\"\n",
        "    Realiza el preprocesamiento completo de los datos.\n",
        "    \"\"\"\n",
        "    # 1. Separar features\n",
        "    numeric_features, categorical_features = categorize_features(df)\n",
        "\n",
        "    # 2. Limpiar datos categ√≥ricos\n",
        "    df = clean_categorical_data(df)\n",
        "\n",
        "    # 3. Reemplazar \"3+\" por \"3\" en Dependents y convertir a num√©rico\n",
        "    df['Dependents'] = df['Dependents'].replace('3+', '3').astype(float)\n",
        "\n",
        "    # 4. Estandarizar variables num√©ricas\n",
        "    scaler = StandardScaler()\n",
        "    df[numeric_features] = scaler.fit_transform(df[numeric_features])\n",
        "\n",
        "    # 5. Codificar variable objetivo Loan_Status (Y -> 1, N -> 0)\n",
        "    df['Loan_Status'] = df['Loan_Status'].map({'Y': 1, 'N': 0})\n",
        "\n",
        "    # 6. Codificar otras Variables\n",
        "    df['Married'] = df['Married'].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "    df['Education'] = df['Education'].map({'Graduate': 1, 'Not Graduate': 0})\n",
        "\n",
        "    df['Self_Employed'] = df['Self_Employed'].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "    # 7. Crear dummies para Property_Area\n",
        "    df = pd.get_dummies(df, columns=['Property_Area'], prefix='', prefix_sep='')\n",
        "    # Convertir solo las columnas dummy a int. Rellenar NaNs con 0 en columnas num√©ricas.\n",
        "    for col in ['Rural', 'Semiurban', 'Urban']:\n",
        "        df[col] = df[col].fillna(0).astype(int)\n",
        "\n",
        "    # 8. Crear dummies para Gender\n",
        "    df = pd.get_dummies(df, columns=['Gender'], prefix='', prefix_sep='')\n",
        "    # Convertir solo las columnas dummy a int. Rellenar NaNs con 0 en columnas num√©ricas.\n",
        "    for col in ['Female', 'Male', 'Unknown']:\n",
        "        df[col] = df[col].fillna(0).astype(int)\n",
        "\n",
        "\n",
        "    # 9. Separar features y target\n",
        "    X = df.drop('Loan_Status', axis=1)\n",
        "    y = df['Loan_Status']\n",
        "\n",
        "    # 10. Guardar informaci√≥n del preprocesamiento\n",
        "    preprocessing_info = {\n",
        "        'numeric_features': numeric_features,\n",
        "        'categorical_features': categorical_features,\n",
        "        'scaler': scaler\n",
        "    }\n",
        "\n",
        "    return X, y, preprocessing_info\n",
        "\n",
        "def print_preprocessing_summary(X, y):\n",
        "    \"\"\"\n",
        "    Imprime un resumen del preprocesamiento.\n",
        "    \"\"\"\n",
        "    print(\"\\n=== Resumen del Preprocesamiento ===\")\n",
        "    print(f\"Dimensiones de X: {X.shape}\")\n",
        "\n",
        "    print(\"\\nDistribuci√≥n de clases:\")\n",
        "    print(pd.Series(y).value_counts(normalize=True).round(3))\n",
        "\n",
        "    print(\"\\nEstad√≠sticas de algunas variables num√©ricas:\")\n",
        "    print(X.describe().round(2).head())"
      ],
      "metadata": {
        "id": "tDZhSzXaHlQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejecutar el Preprocesamiento\n",
        "\n",
        "# Importar y cargar datos\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# 1. Cargar datos\n",
        "dataset = load_dataset(\"13nishit/LoanApprovalPrediction\", streaming=True)\n",
        "df = pd.DataFrame(list(dataset['train'].shuffle(seed=42).take(10000)))\n",
        "\n",
        "# 2. Aplicar preprocesamiento\n",
        "X, y, preprocessing_info = preprocess_data(df)\n",
        "\n",
        "# 3. Imprimir resumen\n",
        "print_preprocessing_summary(X, y)\n",
        "\n",
        "# 4. Verificar las caracter√≠sticas procesadas\n",
        "print(\"\\n=== Caracter√≠sticas procesadas ===\")\n",
        "print(\"\\nCaracter√≠sticas num√©ricas:\")\n",
        "print(preprocessing_info['numeric_features'])\n",
        "print(\"\\nCaracter√≠sticas categ√≥ricas:\")\n",
        "print(preprocessing_info['categorical_features'])\n",
        "\n",
        "# 5. Mostrar informaci√≥n adicional sobre los datos procesados\n",
        "print(\"\\n=== Informaci√≥n adicional ===\")\n",
        "print(f\"N√∫mero total de caracter√≠sticas: {X.shape[1]}\")\n",
        "print(f\"N√∫mero total de observaciones: {X.shape[0]}\")\n",
        "print(\"\\nPrimeras columnas del dataset procesado:\")\n",
        "print(X.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWjxLukCHngU",
        "outputId": "b5bee813-3319-4829-9cae-73dde596e496"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Resumen del Preprocesamiento ===\n",
            "Dimensiones de X: (614, 16)\n",
            "\n",
            "Distribuci√≥n de clases:\n",
            "Loan_Status\n",
            "1    0.687\n",
            "0    0.313\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Estad√≠sticas de algunas variables num√©ricas:\n",
            "       Married  Dependents  Education  Self_Employed  ApplicantIncome  \\\n",
            "count   611.00      599.00     614.00         582.00           614.00   \n",
            "mean      0.65        0.00       0.78           0.14            -0.00   \n",
            "std       0.48        1.00       0.41           0.35             1.00   \n",
            "min       0.00       -0.75       0.00           0.00            -0.86   \n",
            "25%       0.00       -0.75       1.00           0.00            -0.41   \n",
            "\n",
            "       CoapplicantIncome  LoanAmount  Loan_Amount_Term  Credit_History  \\\n",
            "count             614.00      592.00            600.00          614.00   \n",
            "mean               -0.00        0.00              0.00            0.77   \n",
            "std                 1.00        1.00              1.00            0.42   \n",
            "min                -0.55       -1.61             -5.07            0.00   \n",
            "25%                -0.55       -0.54              0.28            1.00   \n",
            "\n",
            "        Rural  Semiurban   Urban  Female   Male  Unknown  \n",
            "count  614.00     614.00  614.00  614.00  614.0   614.00  \n",
            "mean     0.29       0.38    0.33    0.18    0.8     0.02  \n",
            "std      0.45       0.49    0.47    0.39    0.4     0.14  \n",
            "min      0.00       0.00    0.00    0.00    0.0     0.00  \n",
            "25%      0.00       0.00    0.00    0.00    1.0     0.00  \n",
            "\n",
            "=== Caracter√≠sticas procesadas ===\n",
            "\n",
            "Caracter√≠sticas num√©ricas:\n",
            "['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term', 'Dependents']\n",
            "\n",
            "Caracter√≠sticas categ√≥ricas:\n",
            "['Gender', 'Married', 'Education', 'Self_Employed', 'Credit_History', 'Property_Area', 'Loan_Status']\n",
            "\n",
            "=== Informaci√≥n adicional ===\n",
            "N√∫mero total de caracter√≠sticas: 16\n",
            "N√∫mero total de observaciones: 614\n",
            "\n",
            "Primeras columnas del dataset procesado:\n",
            "    Loan_ID  Married  Dependents  Education  Self_Employed  ApplicantIncome  \\\n",
            "0  LP001280      1.0    1.219539          0            0.0        -0.339194   \n",
            "1  LP001345      1.0    1.219539          0            0.0        -0.182740   \n",
            "2  LP001633      1.0    0.233704          1            0.0         0.163259   \n",
            "3  LP002693      1.0    1.219539          1            1.0         0.416860   \n",
            "4  LP002315      1.0    0.233704          1            0.0         0.474527   \n",
            "\n",
            "   CoapplicantIncome  LoanAmount  Loan_Amount_Term  Credit_History  Rural  \\\n",
            "0           0.129539   -0.554431          0.276642             0.0      0   \n",
            "1           0.561501   -0.156840         -2.489775             1.0      0   \n",
            "2           1.925108    0.392771          0.276642             0.0      0   \n",
            "3           1.896379    3.900927          0.276642             1.0      1   \n",
            "4          -0.554487    0.065343         -0.645497             0.0      0   \n",
            "\n",
            "   Semiurban  Urban  Female  Male  Unknown  \n",
            "0          1      0       0     1        0  \n",
            "1          0      1       0     1        0  \n",
            "2          0      1       0     1        0  \n",
            "3          0      0       0     1        0  \n",
            "4          1      0       0     1        0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uD3TKTGVNLdH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos las librer√≠as necesarias\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Cargamos el dataset y lo mezclamos\n",
        "dataset = load_dataset(\"scikit-learn/credit-card-clients\", streaming=True)\n",
        "df = pd.DataFrame(list(dataset['train'].shuffle(seed=42).take(10000)))\n",
        "\n",
        "# 1. Examinamos la informaci√≥n b√°sica del DataFrame\n",
        "print(\"\\n=== Informaci√≥n del DataFrame ===\")\n",
        "print(df.info())\n",
        "\n",
        "# 2. Verificamos los tipos de datos y valores √∫nicos para cada columna\n",
        "print(\"\\n=== Valores √∫nicos por columna ===\")\n",
        "for column in df.columns:\n",
        "    print(f\"\\n{column}:\")\n",
        "    print(f\"Tipo de dato: {df[column].dtype}\")\n",
        "    print(f\"Valores √∫nicos: {df[column].nunique()}\")\n",
        "    print(f\"Primeros valores √∫nicos: {sorted(df[column].unique())[:5]}\")\n",
        "\n",
        "# 3. Verificamos valores nulos\n",
        "print(\"\\n=== Valores nulos ===\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# 4. Estad√≠sticas descriptivas b√°sicas\n",
        "print(\"\\n=== Estad√≠sticas descriptivas ===\")\n",
        "print(df.describe())\n",
        "\n",
        "# 5. Debalance de clases\n",
        "\n",
        "print(\"üìä Distribuci√≥n de la variable objetivo (default.payment.next.month):\")\n",
        "class_dist = df['default.payment.next.month'].value_counts(normalize=True)\n",
        "print(\"\\nPorcentajes:\")\n",
        "for clase, porcentaje in class_dist.items():\n",
        "    print(f\"Clase {clase}: {porcentaje*100:.2f}%\")\n",
        "\n",
        "# Visualizamos la distribuci√≥n con un gr√°fico de barras\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(data=df, x='default.payment.next.month')\n",
        "plt.title('Distribuci√≥n de Defaults en la muestra')\n",
        "plt.xlabel('Default (0: No, 1: S√≠)')\n",
        "plt.ylabel('Cantidad')\n",
        "\n",
        "# A√±adimos los valores exactos sobre cada barra\n",
        "for i in plt.gca().containers[0]:\n",
        "    plt.text(i.get_x() + i.get_width()/2,\n",
        "            i.get_height(),\n",
        "            f'{int(i.get_height())}',\n",
        "            ha='center', va='bottom')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Funciones de Preprocesamiento de datos\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "def categorize_features(df):\n",
        "    \"\"\"\n",
        "    Separa las caracter√≠sticas en num√©ricas y categ√≥ricas.\n",
        "    \"\"\"\n",
        "    # Variables num√©ricas (montos y edad)\n",
        "    numeric_features = [\n",
        "        'LIMIT_BAL', 'AGE',\n",
        "        'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6',\n",
        "        'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6'\n",
        "    ]\n",
        "\n",
        "    # Variables categ√≥ricas\n",
        "    categorical_features = [\n",
        "        'SEX', 'EDUCATION', 'MARRIAGE',\n",
        "        'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6'\n",
        "    ]\n",
        "\n",
        "    return numeric_features, categorical_features\n",
        "\n",
        "def clean_categorical_data(df):\n",
        "    \"\"\"\n",
        "    Limpia y corrige valores en variables categ√≥ricas.\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    # Corregir valores en EDUCATION\n",
        "    # 0, 5 y 6 son valores no definidos, los convertimos a 4 (Others)\n",
        "    df['EDUCATION'] = df['EDUCATION'].replace([0, 5, 6], 4)\n",
        "\n",
        "    # Corregir valores en MARRIAGE\n",
        "    # 0 es un valor no definido, lo convertimos a 3 (Others)\n",
        "    df['MARRIAGE'] = df['MARRIAGE'].replace([0], 3)\n",
        "\n",
        "    return df\n",
        "\n",
        "def preprocess_data(df):\n",
        "    \"\"\"\n",
        "    Realiza el preprocesamiento completo de los datos.\n",
        "    \"\"\"\n",
        "    # 1. Separar features\n",
        "    numeric_features, categorical_features = categorize_features(df)\n",
        "\n",
        "    # 2. Limpiar datos categ√≥ricos\n",
        "    df = clean_categorical_data(df)\n",
        "\n",
        "    # 3. Estandarizar variables num√©ricas\n",
        "    scaler = StandardScaler()\n",
        "    df[numeric_features] = scaler.fit_transform(df[numeric_features])\n",
        "\n",
        "    # 4. Codificar variables categ√≥ricas\n",
        "    label_encoders = {}\n",
        "    for feature in categorical_features:\n",
        "        label_encoders[feature] = LabelEncoder()\n",
        "        df[feature] = label_encoders[feature].fit_transform(df[feature].astype(str))\n",
        "\n",
        "    # 5. Separar features y target\n",
        "    X = df.drop('default.payment.next.month', axis=1)\n",
        "    y = df['default.payment.next.month']\n",
        "\n",
        "    # 6. Guardar informaci√≥n del preprocesamiento\n",
        "    preprocessing_info = {\n",
        "        'numeric_features': numeric_features,\n",
        "        'categorical_features': categorical_features,\n",
        "        'scaler': scaler,\n",
        "        'label_encoders': label_encoders\n",
        "    }\n",
        "\n",
        "    return X, y, preprocessing_info\n",
        "\n",
        "def print_preprocessing_summary(X, y):\n",
        "    \"\"\"\n",
        "    Imprime un resumen del preprocesamiento.\n",
        "    \"\"\"\n",
        "    print(\"\\n=== Resumen del Preprocesamiento ===\")\n",
        "    print(f\"Dimensiones de X: {X.shape}\")\n",
        "\n",
        "    print(\"\\nDistribuci√≥n de clases:\")\n",
        "    print(pd.Series(y).value_counts(normalize=True).round(3))\n",
        "\n",
        "    print(\"\\nEstad√≠sticas de algunas variables num√©ricas:\")\n",
        "    print(X.describe().round(2).head())\n",
        "\n",
        "    # Ejecutar el Preprocesamiento\n",
        "\n",
        "# Importar y cargar datos\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Cargar datos\n",
        "dataset = load_dataset(\"scikit-learn/credit-card-clients\", streaming=True)\n",
        "df = pd.DataFrame(list(dataset['train'].shuffle(seed=42).take(10000)))\n",
        "\n",
        "# 2. Aplicar preprocesamiento\n",
        "X, y, preprocessing_info = preprocess_data(df)\n",
        "\n",
        "# 3. Imprimir resumen\n",
        "print_preprocessing_summary(X, y)\n",
        "\n",
        "# 4. Verificar las caracter√≠sticas procesadas\n",
        "print(\"\\n=== Caracter√≠sticas procesadas ===\")\n",
        "print(\"\\nCaracter√≠sticas num√©ricas:\")\n",
        "print(preprocessing_info['numeric_features'])\n",
        "print(\"\\nCaracter√≠sticas categ√≥ricas:\")\n",
        "print(preprocessing_info['categorical_features'])\n",
        "\n",
        "# 5. Mostrar informaci√≥n adicional sobre los datos procesados\n",
        "print(\"\\n=== Informaci√≥n adicional ===\")\n",
        "print(f\"N√∫mero total de caracter√≠sticas: {X.shape[1]}\")\n",
        "print(f\"N√∫mero total de observaciones: {X.shape[0]}\")\n",
        "print(\"\\nPrimeras columnas del dataset procesado:\")\n",
        "print(X.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "fx2q6FuONKRk",
        "outputId": "cea57a30-4fac-46e9-8123-8ae57690c033"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "partially initialized module 'pandas' has no attribute '_pandas_parser_CAPI' (most likely due to a circular import)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-ee95e3a7fa4d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Importamos las librer√≠as necesarias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    136\u001b[0m )\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplotting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtseries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_print_versions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/api/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\"\"\" public toolkit API \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m from pandas.api import (\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mindexers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0minterchange\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/api/typing/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# TODO: Can't import Styler without importing jinja2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# from pandas.io.formats.style import Styler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_json\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mJsonReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStataReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/json/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m from pandas.io.json._json import (\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mread_json\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mto_json\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mujson_dumps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mujson_loads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mparse_table_schema\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m )\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreaders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mTYPE_CHECKING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m from pandas.io.parsers.readers import (\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mTextFileReader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mTextParser\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mread_csv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mread_fwf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_libs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_libs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparsers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSTR_NA_VALUES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m from pandas.errors import (\n\u001b[1;32m     34\u001b[0m     \u001b[0mAbstractMethodError\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36minit pandas._libs.parsers\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'pandas' has no attribute '_pandas_parser_CAPI' (most likely due to a circular import)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preparaci√≥n para el entrenamiento"
      ],
      "metadata": {
        "id": "NJBtgSeOHriZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- PREPARACI√ìN PARA EL ENTRENAMIENTO ---\n",
        "\n",
        "# Importamos las bibliotecas necesarias\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.decomposition import PCA\n",
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Fijamos la semilla aleatoria para garantizar reproducibilidad\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "\n",
        "# Divisi√≥n estratificada de datos (80% entrenamiento, 20% prueba)\n",
        "# stratify=y asegura que la proporci√≥n de las clases se mantenga\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,              # Matriz de caracter√≠sticas\n",
        "    y,              # Vector objetivo (default/no default)\n",
        "    test_size=0.2,  # 20% para prueba\n",
        "    random_state=RANDOM_STATE,\n",
        "    stratify=y      # Mantiene proporci√≥n de clases\n",
        ")\n",
        "\n",
        "# Para XGBoost, necesitamos un conjunto de validaci√≥n\n",
        "X_train_xgb, X_val_xgb, y_train_xgb, y_val_xgb = train_test_split(\n",
        "    X_train, y_train,\n",
        "    test_size=0.2,\n",
        "    random_state=RANDOM_STATE,\n",
        "    stratify=y_train\n",
        ")\n",
        "\n",
        "# Definici√≥n de los modelos a entrenar\n",
        "models = {\n",
        "\n",
        "    # Random Forest\n",
        "    \"RandomForest\": RandomForestClassifier(\n",
        "        n_estimators=100,       # N√∫mero de √°rboles en el bosque\n",
        "        max_depth=None,         # Permite √°rboles profundos\n",
        "        min_samples_leaf=5,     # Control b√°sico de overfitting\n",
        "        max_features='sqrt',    # N√∫mero de features a considerar en cada split\n",
        "        n_jobs=-1,             # Usa todos los n√∫cleos disponibles\n",
        "        random_state=RANDOM_STATE\n",
        "    ),\n",
        "\n",
        "    # XGBoost\n",
        "    \"XGBoost\": xgb.XGBClassifier(\n",
        "        learning_rate=0.1,      # Tama√±o de paso en cada iteraci√≥n\n",
        "        n_estimators=100,       # N√∫mero m√°ximo de √°rboles\n",
        "        max_depth=6,           # Profundidad fija para control de complejidad\n",
        "        early_stopping_rounds=20,# Detiene el entrenamiento si no hay mejora en 20 rondas\n",
        "        min_child_weight=1,     # Control de overfitting similar a min_samples_leaf\n",
        "        subsample=0.8,          # Fracci√≥n de muestras para cada √°rbol\n",
        "        colsample_bytree=0.8,   # Fracci√≥n de features para cada √°rbol\n",
        "        eval_metric=['auc', 'error', 'logloss'],  # M√∫ltiples m√©tricas de evaluaci√≥n\n",
        "        random_state=RANDOM_STATE,\n",
        "        enable_categorical=False # Deshabilitamos caracter√≠sticas categ√≥ricas\n",
        "    ),\n",
        "\n",
        "    # K-Nearest Neighbors (KNN)\n",
        "    # La elecci√≥n de k se basa en la ra√≠z cuadrada del n√∫mero de muestras\n",
        "    \"KNN\": KNeighborsClassifier(\n",
        "        n_neighbors=int(np.sqrt(len(X_train))),  # k basado en regla de la ra√≠z\n",
        "        weights='uniform',       # Todos los vecinos tienen el mismo peso\n",
        "        metric='euclidean'      # Distancia euclidiana para similitud\n",
        "    ),\n",
        "\n",
        "    # Support Vector Machine (SVM)\n",
        "    # Utilizamos kernel RBF para capturar relaciones no lineales\n",
        "    \"SVM\": SVC(\n",
        "        kernel='rbf',           # Tipo de kernel: 'linear', 'poly', 'rbf', 'sigmoid'\n",
        "        C=1.0,                  # Par√°metro de margen suave (soft margin):\n",
        "                               # - C grande: margen m√°s estrecho, menos errores permitidos\n",
        "                               # - C peque√±o: margen m√°s amplio, m√°s errores permitidos\n",
        "        gamma='scale',          # Coeficiente Œ≥ para kernel RBF: exp(-Œ≥||x‚ÇÅ - x‚ÇÇ||¬≤)\n",
        "                               # 'scale' calcula Œ≥ = 1 / (n_features * X.var())\n",
        "        random_state=RANDOM_STATE\n",
        "    ),\n",
        "\n",
        "    # PCA + KNN\n",
        "    # Combinamos reducci√≥n de dimensionalidad con clasificaci√≥n\n",
        "    \"PCA-KNN\": {\n",
        "        'pca': PCA(\n",
        "            n_components=0.95,   # Mantener 95% de la varianza explicada\n",
        "            random_state=RANDOM_STATE\n",
        "        ),\n",
        "        'knn': KNeighborsClassifier(\n",
        "            n_neighbors=5,       # k inicial para clasificaci√≥n\n",
        "            weights='uniform',\n",
        "            metric='euclidean'\n",
        "        )\n",
        "    }\n",
        "}\n",
        "\n",
        "# Diccionarios para almacenar resultados\n",
        "predictions = {}      # Predicciones binarias (0/1)\n",
        "probabilities = {}    # Probabilidades [0,1]\n",
        "xgb_results = {}     # Para almacenar resultados de evaluaci√≥n de XGBoost\n",
        "components = {}      # Almacenar√° componentes principales para PCA\n",
        "\n",
        "# Informaci√≥n sobre la divisi√≥n de datos\n",
        "print(\"=== Informaci√≥n de la Divisi√≥n de Datos ===\")\n",
        "print(f\"Dimensiones de X_train: {X_train.shape}\")\n",
        "print(f\"Dimensiones de X_test: {X_test.shape}\")\n",
        "print(f\"Dimensiones de X_val_xgb (para XGBoost): {X_val_xgb.shape}\")\n",
        "print(\"\\nDistribuci√≥n de clases:\")\n",
        "print(\"\\nConjunto de entrenamiento:\")\n",
        "print(pd.Series(y_train).value_counts(normalize=True).round(3))\n",
        "print(\"\\nConjunto de prueba:\")\n",
        "print(pd.Series(y_test).value_counts(normalize=True).round(3))\n",
        "print(\"\\nConjunto de validaci√≥n XGBoost:\")\n",
        "print(pd.Series(y_val_xgb).value_counts(normalize=True).round(3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_fgDtRuIBSe",
        "outputId": "47fb6704-556a-4d51-a239-840e2afa7937"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Informaci√≥n de la Divisi√≥n de Datos ===\n",
            "Dimensiones de X_train: (8000, 24)\n",
            "Dimensiones de X_test: (2000, 24)\n",
            "Dimensiones de X_val_xgb (para XGBoost): (1600, 24)\n",
            "\n",
            "Distribuci√≥n de clases:\n",
            "\n",
            "Conjunto de entrenamiento:\n",
            "default.payment.next.month\n",
            "0    0.776\n",
            "1    0.224\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Conjunto de prueba:\n",
            "default.payment.next.month\n",
            "0    0.776\n",
            "1    0.224\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Conjunto de validaci√≥n XGBoost:\n",
            "default.payment.next.month\n",
            "0    0.776\n",
            "1    0.224\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Iniciar entrenamiento"
      ],
      "metadata": {
        "id": "iSh1pwgDPj_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- ENTRENAMIENTO DE MODELOS ---\n",
        "\n",
        "def print_model_info(name, model, X_train):\n",
        "    \"\"\"\n",
        "    Imprime informaci√≥n relevante seg√∫n el tipo de modelo\n",
        "    \"\"\"\n",
        "    print(f\"\\nInformaci√≥n para {name}:\")\n",
        "\n",
        "    if hasattr(model, 'feature_importances_'):\n",
        "        # Para modelos basados en √°rboles que tienen importancia de caracter√≠sticas\n",
        "        importances = pd.DataFrame({\n",
        "            'Feature': X_train.columns,\n",
        "            'Importance': model.feature_importances_\n",
        "        }).sort_values('Importance', ascending=False)\n",
        "\n",
        "        print(\"\\nTop 5 caracter√≠sticas m√°s importantes:\")\n",
        "        print(importances.head())\n",
        "        print(\"\\nTop 5 caracter√≠sticas menos importantes:\")\n",
        "        print(importances.tail())\n",
        "\n",
        "    # Informaci√≥n espec√≠fica para cada tipo de modelo\n",
        "    if name == \"RandomForest\":\n",
        "        print(f\"\\nN√∫mero de √°rboles: {model.n_estimators}\")\n",
        "        print(f\"M√°xima profundidad: {model.max_depth if model.max_depth else 'No limitada'}\")\n",
        "        print(f\"Features por split: {model.max_features}\")\n",
        "    elif name == \"XGBoost\":\n",
        "        print(\"\\nMejor iteraci√≥n: \", model.best_iteration if hasattr(model, 'best_iteration') else None)\n",
        "        print(f\"Tasa de aprendizaje: {model.learning_rate}\")\n",
        "        print(f\"N√∫mero de estimadores: {model.n_estimators}\")\n",
        "    elif name == \"KNN\":\n",
        "        print(f\"\\nN√∫mero de vecinos (k): {model.n_neighbors}\")\n",
        "        print(f\"M√©trica de distancia: {model.metric}\")\n",
        "    elif name == \"SVM\":\n",
        "        print(f\"\\nTipo de kernel: {model.kernel}\")\n",
        "        print(f\"Par√°metro C (regularizaci√≥n): {model.C}\")\n",
        "        print(f\"Par√°metro gamma: {model.gamma}\")\n",
        "    elif name == \"PCA-KNN\":\n",
        "        print(f\"\\nN√∫mero de componentes principales: {model['pca'].n_components_}\")\n",
        "        print(f\"Varianza explicada acumulada: {np.sum(model['pca'].explained_variance_ratio_):.2f}\")\n",
        "        print(f\"N√∫mero de vecinos (k): {model['knn'].n_neighbors}\")\n",
        "        print(f\"M√©trica de distancia: {model['knn'].metric}\")\n",
        "\n",
        "# Iteramos sobre cada modelo para entrenamiento y predicciones\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n=== Entrenando modelo: {name} ===\")\n",
        "\n",
        "    # Entrenamiento del modelo\n",
        "    if name == \"XGBoost\":\n",
        "        # Usamos los conjuntos de validaci√≥n previamente creados\n",
        "        model.fit(\n",
        "            X_train_xgb, y_train_xgb,\n",
        "            eval_set=[(X_train_xgb, y_train_xgb), (X_val_xgb, y_val_xgb)],\n",
        "            verbose=False\n",
        "        )\n",
        "\n",
        "        predictions[name] = model.predict(X_test)\n",
        "        probabilities[name] = model.predict_proba(X_test)[:, 1]\n",
        "    elif name == \"PCA-KNN\":\n",
        "        # Aplicamos PCA primero\n",
        "        components[name] = model['pca'].fit_transform(X_train)\n",
        "        model['knn'].fit(components[name], y_train)\n",
        "\n",
        "        # Transformamos el conjunto de prueba con el PCA ajustado\n",
        "        X_test_pca = model['pca'].transform(X_test)\n",
        "        predictions[name] = model['knn'].predict(X_test_pca)\n",
        "        probabilities[name] = model['knn'].predict_proba(X_test_pca)[:, 1]\n",
        "    elif name == \"SVM\":\n",
        "        # Configuramos probability=True para habilitar predict_proba\n",
        "        model.set_params(probability=True)\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions[name] = model.predict(X_test)\n",
        "        probabilities[name] = model.predict_proba(X_test)[:, 1]\n",
        "    else:\n",
        "        # Para RandomForest y KNN\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions[name] = model.predict(X_test)\n",
        "        probabilities[name] = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Mostrar informaci√≥n del modelo\n",
        "    print_model_info(name, model, X_train)\n",
        "\n",
        "# Calculamos y mostramos el tiempo de ejecuci√≥n promedio para predicciones\n",
        "import time\n",
        "\n",
        "print(\"\\n=== Evaluaci√≥n de Tiempo de Predicci√≥n ===\")\n",
        "for name, model in models.items():\n",
        "    times = []\n",
        "    for _ in range(100):  # 100 predicciones para promedio estable\n",
        "        start_time = time.time()\n",
        "        if name == \"PCA-KNN\":\n",
        "            X_test_pca = model['pca'].transform(X_test[:100])\n",
        "            model['knn'].predict(X_test_pca)\n",
        "        else:\n",
        "            model.predict(X_test[:100])\n",
        "        times.append(time.time() - start_time)\n",
        "\n",
        "    print(f\"\\n{name}:\")\n",
        "    print(f\"Tiempo promedio de predicci√≥n: {np.mean(times)*1000:.2f} ms\")\n",
        "    print(f\"Desviaci√≥n est√°ndar: {np.std(times)*1000:.2f} ms\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z14LMNu4Pos9",
        "outputId": "a5659a7e-3906-43ef-bdcd-54f9a81cb7c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Entrenando modelo: RandomForest ===\n",
            "\n",
            "Informaci√≥n para RandomForest:\n",
            "\n",
            "Top 5 caracter√≠sticas m√°s importantes:\n",
            "      Feature  Importance\n",
            "6       PAY_0    0.129697\n",
            "7       PAY_2    0.061898\n",
            "0          ID    0.057274\n",
            "12  BILL_AMT1    0.048693\n",
            "1   LIMIT_BAL    0.046750\n",
            "\n",
            "Top 5 caracter√≠sticas menos importantes:\n",
            "      Feature  Importance\n",
            "10      PAY_5    0.028087\n",
            "11      PAY_6    0.019895\n",
            "3   EDUCATION    0.011421\n",
            "2         SEX    0.008520\n",
            "4    MARRIAGE    0.008219\n",
            "\n",
            "N√∫mero de √°rboles: 100\n",
            "M√°xima profundidad: No limitada\n",
            "Features por split: sqrt\n",
            "\n",
            "=== Entrenando modelo: XGBoost ===\n",
            "\n",
            "Informaci√≥n para XGBoost:\n",
            "\n",
            "Top 5 caracter√≠sticas m√°s importantes:\n",
            "   Feature  Importance\n",
            "6    PAY_0    0.304871\n",
            "8    PAY_3    0.066769\n",
            "11   PAY_6    0.038851\n",
            "10   PAY_5    0.038670\n",
            "7    PAY_2    0.037068\n",
            "\n",
            "Top 5 caracter√≠sticas menos importantes:\n",
            "     Feature  Importance\n",
            "0         ID    0.023862\n",
            "5        AGE    0.023066\n",
            "4   MARRIAGE    0.022867\n",
            "3  EDUCATION    0.021780\n",
            "2        SEX    0.021650\n",
            "\n",
            "Mejor iteraci√≥n:  31\n",
            "Tasa de aprendizaje: 0.1\n",
            "N√∫mero de estimadores: 100\n",
            "\n",
            "=== Entrenando modelo: KNN ===\n",
            "\n",
            "Informaci√≥n para KNN:\n",
            "\n",
            "N√∫mero de vecinos (k): 89\n",
            "M√©trica de distancia: euclidean\n",
            "\n",
            "=== Entrenando modelo: SVM ===\n",
            "\n",
            "Informaci√≥n para SVM:\n",
            "\n",
            "Tipo de kernel: rbf\n",
            "Par√°metro C (regularizaci√≥n): 1.0\n",
            "Par√°metro gamma: scale\n",
            "\n",
            "=== Entrenando modelo: PCA-KNN ===\n",
            "\n",
            "Informaci√≥n para PCA-KNN:\n",
            "\n",
            "N√∫mero de componentes principales: 1\n",
            "Varianza explicada acumulada: 1.00\n",
            "N√∫mero de vecinos (k): 5\n",
            "M√©trica de distancia: euclidean\n",
            "\n",
            "=== Evaluaci√≥n de Tiempo de Predicci√≥n ===\n",
            "\n",
            "RandomForest:\n",
            "Tiempo promedio de predicci√≥n: 38.41 ms\n",
            "Desviaci√≥n est√°ndar: 3.81 ms\n",
            "\n",
            "XGBoost:\n",
            "Tiempo promedio de predicci√≥n: 8.00 ms\n",
            "Desviaci√≥n est√°ndar: 0.94 ms\n",
            "\n",
            "KNN:\n",
            "Tiempo promedio de predicci√≥n: 17.91 ms\n",
            "Desviaci√≥n est√°ndar: 1.29 ms\n",
            "\n",
            "SVM:\n",
            "Tiempo promedio de predicci√≥n: 27.50 ms\n",
            "Desviaci√≥n est√°ndar: 2.25 ms\n",
            "\n",
            "PCA-KNN:\n",
            "Tiempo promedio de predicci√≥n: 8.86 ms\n",
            "Desviaci√≥n est√°ndar: 1.53 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##M√âTRICAS DE EVALUACI√ìN DE MODELOS DE RIESGO CREDITICIO"
      ],
      "metadata": {
        "id": "VmHE5_YZ5QyY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Evaluaci√≥n y M√©tricas Tradicionales ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report, accuracy_score,\n",
        "    precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
        ")\n",
        "\n",
        "class ModelEvaluator:\n",
        "    def __init__(self, y_true, predictions, probabilities):\n",
        "        \"\"\"\n",
        "        Inicializa el evaluador con los datos necesarios.\n",
        "\n",
        "        Par√°metros:\n",
        "        -----------\n",
        "        y_true: array-like\n",
        "            Etiquetas verdaderas\n",
        "        predictions: dict\n",
        "            Diccionario con predicciones de cada modelo\n",
        "        probabilities: dict\n",
        "            Diccionario con probabilidades de cada modelo\n",
        "        \"\"\"\n",
        "        # Asegurar que los datos est√©n en el formato correcto\n",
        "        self.y_true = np.array(y_true)\n",
        "        self.predictions = {k: np.array(v) for k, v in predictions.items()}\n",
        "        self.probabilities = {k: np.array(v) for k, v in probabilities.items()}\n",
        "        self.colors = [\"#EDF2FB\", \"#ABC4FF\"]\n",
        "\n",
        "    def create_metrics_table(self):\n",
        "        \"\"\"\n",
        "        Crea una tabla comparativa con las m√©tricas de todos los modelos.\n",
        "        \"\"\"\n",
        "        metrics = []\n",
        "        for name, pred in self.predictions.items():\n",
        "            try:\n",
        "                metric_dict = {\n",
        "                    'Modelo': name,\n",
        "                    'Accuracy': accuracy_score(self.y_true, pred),\n",
        "                    'Precision': precision_score(self.y_true, pred, zero_division=0),\n",
        "                    'Recall': recall_score(self.y_true, pred),\n",
        "                    'F1-Score': f1_score(self.y_true, pred),\n",
        "                    'AUC-ROC': roc_auc_score(self.y_true, self.probabilities[name])\n",
        "                }\n",
        "            except Exception as e:\n",
        "                print(f\"Error calculando m√©tricas para {name}: {str(e)}\")\n",
        "                metric_dict = {\n",
        "                    'Modelo': name,\n",
        "                    'Accuracy': 'Error',\n",
        "                    'Precision': 'Error',\n",
        "                    'Recall': 'Error',\n",
        "                    'F1-Score': 'Error',\n",
        "                    'AUC-ROC': 'Error'\n",
        "                }\n",
        "\n",
        "            metrics.append(metric_dict)\n",
        "\n",
        "        df_metrics = pd.DataFrame(metrics)\n",
        "\n",
        "        # Formatear las columnas num√©ricas\n",
        "        numeric_columns = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC-ROC']\n",
        "\n",
        "        for col in numeric_columns:\n",
        "            if col in df_metrics.columns:\n",
        "                df_metrics[col] = pd.to_numeric(df_metrics[col], errors='ignore')\n",
        "                df_metrics[col] = df_metrics[col].apply(\n",
        "                    lambda x: f\"{x:.4f}\" if isinstance(x, (int, float)) else x\n",
        "                )\n",
        "\n",
        "        return df_metrics\n",
        "\n",
        "    def plot_confusion_matrices(self):\n",
        "        \"\"\"\n",
        "        Visualiza las matrices de confusi√≥n para modelos de clasificaci√≥n.\n",
        "        \"\"\"\n",
        "        n_models = len(self.predictions)\n",
        "        fig, axes = plt.subplots(1, n_models, figsize=(5*n_models, 4))\n",
        "        if n_models == 1:\n",
        "            axes = [axes]\n",
        "\n",
        "        cmap = sns.color_palette(self.colors, as_cmap=True)\n",
        "\n",
        "        for idx, (name, y_pred) in enumerate(self.predictions.items()):\n",
        "            try:\n",
        "                cm = confusion_matrix(self.y_true, y_pred)\n",
        "                sns.heatmap(\n",
        "                    cm,\n",
        "                    annot=True,\n",
        "                    fmt='d',\n",
        "                    ax=axes[idx],\n",
        "                    cmap=cmap,\n",
        "                    cbar=False,\n",
        "                    linewidths=1,\n",
        "                    linecolor='gray',\n",
        "                    square=True\n",
        "                )\n",
        "                axes[idx].set_title(f'Matriz de Confusi√≥n\\n{name}')\n",
        "                axes[idx].set_xlabel('Predicci√≥n')\n",
        "                axes[idx].set_ylabel('Valor Real')\n",
        "                axes[idx].set_xticklabels(['No Default', 'Default'])\n",
        "                axes[idx].set_yticklabels(['No Default', 'Default'], rotation=0)\n",
        "            except Exception as e:\n",
        "                print(f\"Error al crear matriz de confusi√≥n para {name}: {str(e)}\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        return fig\n",
        "\n",
        "    def plot_roc_curves(self):\n",
        "        \"\"\"\n",
        "        Visualiza las curvas ROC para modelos de clasificaci√≥n.\n",
        "        \"\"\"\n",
        "        fig, ax = plt.subplots(figsize=(10, 6))\n",
        "        colors = ['blue', 'orange', 'green', 'red']\n",
        "\n",
        "        for (name, probs), color in zip(self.probabilities.items(), colors):\n",
        "            try:\n",
        "                fpr, tpr, _ = roc_curve(self.y_true, probs)\n",
        "                auc = roc_auc_score(self.y_true, probs)\n",
        "                ax.plot(fpr, tpr, color=color, lw=2,\n",
        "                       label=f'{name} (AUC = {auc:.3f})')\n",
        "            except Exception as e:\n",
        "                print(f\"Error al crear curva ROC para {name}: {str(e)}\")\n",
        "\n",
        "        ax.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
        "        ax.set(xlim=[0.0, 1.0], ylim=[0.0, 1.05],\n",
        "               xlabel='Tasa de Falsos Positivos',\n",
        "               ylabel='Tasa de Verdaderos Positivos',\n",
        "               title='Curvas ROC para los Modelos de Predicci√≥n de Default')\n",
        "        ax.legend(loc=\"lower right\")\n",
        "        ax.grid(True, alpha=0.3)\n",
        "\n",
        "        return fig\n",
        "\n",
        "    def evaluate_all(self):\n",
        "        \"\"\"\n",
        "        Ejecuta todas las evaluaciones y muestra los resultados.\n",
        "        \"\"\"\n",
        "        # Tabla de m√©tricas\n",
        "        try:\n",
        "            metrics_table = self.create_metrics_table()\n",
        "            print(\"\\n=== Tabla Comparativa de M√©tricas ===\")\n",
        "            print(metrics_table.to_string(index=False))\n",
        "        except Exception as e:\n",
        "            print(f\"Error al crear tabla de m√©tricas: {str(e)}\")\n",
        "\n",
        "        # Matrices de confusi√≥n\n",
        "        print(\"\\n=== Matrices de Confusi√≥n ===\")\n",
        "        cm_fig = self.plot_confusion_matrices()\n",
        "        if cm_fig:\n",
        "            plt.show()\n",
        "\n",
        "        # Curvas ROC\n",
        "        print(\"\\n=== Curvas ROC ===\")\n",
        "        roc_fig = self.plot_roc_curves()\n",
        "        if roc_fig:\n",
        "            plt.show()\n",
        "\n",
        "def evaluar_modelos(y_test, predictions, probabilities):\n",
        "    \"\"\"\n",
        "    Funci√≥n auxiliar para ejecutar la evaluaci√≥n simplificada de modelos.\n",
        "\n",
        "    Par√°metros:\n",
        "    -----------\n",
        "    y_test : array-like\n",
        "        Etiquetas verdaderas\n",
        "    predictions : dict\n",
        "        Diccionario con predicciones de cada modelo\n",
        "    probabilities : dict\n",
        "        Diccionario con probabilidades de cada modelo\n",
        "    \"\"\"\n",
        "    evaluator = ModelEvaluator(y_test, predictions, probabilities)\n",
        "    evaluator.evaluate_all()\n",
        "\n",
        "# Ejemplo de uso:\n",
        "evaluar_modelos(y_test, predictions, probabilities)"
      ],
      "metadata": {
        "id": "FzkNjCzWC89h",
        "outputId": "4039cc0d-d378-4eb8-fbc1-23a8db19be60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1fd7cd48a7a8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# --- Evaluaci√≥n y M√©tricas Tradicionales ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_init\u001b[0m  \u001b[0;31m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m from pandas.core.api import (\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0;31m# dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mArrowDtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFlags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m from pandas.core.groupby import (\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mGrouper\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mNamedAgg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/groupby/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m from pandas.core.groupby.generic import (\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mDataFrameGroupBy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mNamedAgg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mSeriesGroupBy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m )\n\u001b[1;32m     67\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m from pandas.core.groupby import (\n\u001b[1;32m     70\u001b[0m     \u001b[0mbase\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0msanitize_masked_array\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m )\n\u001b[0;32m--> 149\u001b[0;31m from pandas.core.generic import (\n\u001b[0m\u001b[1;32m    150\u001b[0m     \u001b[0mNDFrame\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0mmake_doc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    150\u001b[0m )\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m from pandas.core import (\n\u001b[0m\u001b[1;32m    153\u001b[0m     \u001b[0malgorithms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0malgos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0marraylike\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mlength_of_indexer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m )\n\u001b[0;32m---> 79\u001b[0;31m from pandas.core.indexes.api import (\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mMultiIndex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m )\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategory\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCategoricalIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetimes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDatetimeIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterval\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIntervalIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/datetimes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mmaybe_extract_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m )\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetimelike\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDatetimeTimedeltaMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextension\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minherit_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/datetimelike.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     67\u001b[0m )\n\u001b[1;32m     68\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextension\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNDArrayBackedExtensionIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRangeIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimedeltas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_timedelta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mRangeIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \"\"\"\n\u001b[1;32m     68\u001b[0m     \u001b[0mImmutable\u001b[0m \u001b[0mIndex\u001b[0m \u001b[0mimplementing\u001b[0m \u001b[0ma\u001b[0m \u001b[0mmonotonic\u001b[0m \u001b[0minteger\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mRangeIndex\u001b[0;34m()\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m     @deprecate_nonkeyword_arguments(\n\u001b[0m\u001b[1;32m    596\u001b[0m         \u001b[0mversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"3.0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowed_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"self\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sort_values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mdecorate\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mold_sig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mallowed_args\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/inspect.py\u001b[0m in \u001b[0;36msignature\u001b[0;34m(obj, follow_wrapped, globals, locals, eval_str)\u001b[0m\n\u001b[1;32m   3261\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_wrapped\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3262\u001b[0m     \u001b[0;34m\"\"\"Get a signature object for the passed callable.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3263\u001b[0;31m     return Signature.from_callable(obj, follow_wrapped=follow_wrapped,\n\u001b[0m\u001b[1;32m   3264\u001b[0m                                    globals=globals, locals=locals, eval_str=eval_str)\n\u001b[1;32m   3265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/inspect.py\u001b[0m in \u001b[0;36mfrom_callable\u001b[0;34m(cls, obj, follow_wrapped, globals, locals, eval_str)\u001b[0m\n\u001b[1;32m   3009\u001b[0m                       follow_wrapped=True, globals=None, locals=None, eval_str=False):\n\u001b[1;32m   3010\u001b[0m         \u001b[0;34m\"\"\"Constructs Signature for the given callable object.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3011\u001b[0;31m         return _signature_from_callable(obj, sigcls=cls,\n\u001b[0m\u001b[1;32m   3012\u001b[0m                                         \u001b[0mfollow_wrapper_chains\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_wrapped\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3013\u001b[0m                                         globals=globals, locals=locals, eval_str=eval_str)\n",
            "\u001b[0;32m/usr/lib/python3.11/inspect.py\u001b[0m in \u001b[0;36m_signature_from_callable\u001b[0;34m(obj, follow_wrapper_chains, skip_bound_arg, globals, locals, eval_str, sigcls)\u001b[0m\n\u001b[1;32m   2521\u001b[0m         \u001b[0;31m# If it's a pure Python function, or an object that is duck type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2522\u001b[0m         \u001b[0;31m# of a Python function (Cython functions, for instance), then:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2523\u001b[0;31m         return _signature_from_function(sigcls, obj,\n\u001b[0m\u001b[1;32m   2524\u001b[0m                                         \u001b[0mskip_bound_arg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_bound_arg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2525\u001b[0m                                         globals=globals, locals=locals, eval_str=eval_str)\n",
            "\u001b[0;32m/usr/lib/python3.11/inspect.py\u001b[0m in \u001b[0;36m_signature_from_function\u001b[0;34m(cls, func, skip_bound_arg, globals, locals, eval_str)\u001b[0m\n\u001b[1;32m   2374\u001b[0m         \u001b[0mkind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_POSITIONAL_ONLY\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mposonly_left\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_POSITIONAL_OR_KEYWORD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2375\u001b[0m         \u001b[0mannotation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_empty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2376\u001b[0;31m         parameters.append(Parameter(name, annotation=annotation,\n\u001b[0m\u001b[1;32m   2377\u001b[0m                                     kind=kind))\n\u001b[1;32m   2378\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mposonly_left\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/inspect.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, kind, default, annotation)\u001b[0m\n\u001b[1;32m   2667\u001b[0m     \u001b[0mempty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2669\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_empty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_empty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2670\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2671\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ParameterKind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ee3bBvHKC-pX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}